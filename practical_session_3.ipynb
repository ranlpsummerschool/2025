{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e51e4575",
   "metadata": {},
   "source": [
    "# RANLP 2025 Practical — Prompting & Fine‑tuning Large Language Models\n",
    "**Instructor:** Msc. Ernesto Luis Estevanell‑Valladares\n",
    "\n",
    "Welcome. Today we’ll teach language models to do two things people ask for every day: **answer questions** and **translate text**. Think of the little answer boxes you see in search, or the moment a translation unlocks a message. We’ll start small, compare simple prompting decisions, measure what we get, and then fine‑tune compact models to do better. As we go, we’ll explain ideas in plain language so the code never feels mysterious.\n",
    "\n",
    "This practical stands on its own. You’ll meet the tasks (Question Answering with **SQuAD** and English→Spanish translation with an **OPUS** subset), the models (**GPT‑2** and **T5**), and a workflow you can reuse: look at a few examples, set sensible length limits from the data, try a clear prompt with a basic decoding choice, measure quality, and then fine‑tune and compare again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0412e5",
   "metadata": {},
   "source": [
    "## How we’ll work\n",
    "\n",
    "We will walk the same path twice. First on **question answering** with SQuAD, then on **translation** with OPUS. Each time we’ll skim a few examples, choose practical length limits, try a clear prompt and a basic decoding setting, measure, and then fine‑tune a small model and check the result again.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ce551e",
   "metadata": {},
   "source": [
    "### Why these architectures make sense for today’s tasks\n",
    "\n",
    "Question answering and translation both require writing text *conditioned* on something: a passage + question, or a source sentence. A decoder‑only model like GPT‑2 conditions on that information by putting it in the same sequence it continues. An encoder–decoder like T5 separates the “read” and “write” steps: the encoder builds a representation of the input, and the decoder generates while looking back at it. You’ll see this difference reflected in how we set up inputs for each model in the code that follows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e284689",
   "metadata": {},
   "source": [
    "## The datasets\n",
    "\n",
    "**SQuAD** is a collection of questions written about Wikipedia articles, each with an answer found in the text. It’s a standard way to check whether a system can read and reply accurately to a question.\n",
    "\n",
    "**OPUS** is a large, open collection of translated sentence pairs. **OPUS‑100** is an English‑centric slice covering many languages; we’ll work with a small English→Spanish subset so runs stay fast while still feeling realistic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79069794",
   "metadata": {},
   "source": [
    "### A quick note on runtime\n",
    "\n",
    "To keep things comfortable on classroom GPUs, we’ll use small subsets. Treat absolute scores as illustrative; focus on **relative** improvements as we change prompts, decoding, and fine‑tune the models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3208c552",
   "metadata": {},
   "source": [
    "### Small helpers you’ll see in the code\n",
    "\n",
    "We use a few tiny utilities to keep the notebook readable. `human_time` prints friendly timings, `peek` shows a tidy slice of a dataset without flooding the screen, and `clear_memory` frees GPU memory when we swap models. Nothing magical—just quality‑of‑life tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65365549-ce44-4f5c-bc39-d853dbaf0403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip uninstall -q -y torch torchvision torchaudio transformers datasets evaluate sacrebleu sentencepiece accelerate trl langdetect langcodes pandas matplotlib tf-keras peft\n",
    "#%pip uninstall -q -y tensorflow keras tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5cc5e63-0e43-4b3c-9814-662d31e4b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -q torch torchaudio --index-url https://download.pytorch.org/whl/cu126\n",
    "#%pip install -q transformers datasets evaluate sacrebleu sentencepiece trl langdetect accelerate>=0.21.0 peft langcodes pandas matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e305337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Part 0 — Setup\n",
    "import os, random, math, json, time, re\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "import evaluate\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f45690a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helpers ready.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import gc\n",
    "\n",
    "def human_time(seconds: float) -> str:\n",
    "    m, s = divmod(int(seconds), 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return f\"{h:d}h {m:02d}m {s:02d}s\"\n",
    "\n",
    "def peek(ds: Dataset, n: int = 2):\n",
    "    for i in range(n):\n",
    "        print(json.dumps(ds[i], ensure_ascii=False, indent=2))\n",
    "\n",
    "def clear_memory():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()\n",
    "    \n",
    "print('Helpers ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39e64f9",
   "metadata": {},
   "source": [
    "# Part A — Question Answering with SQuAD\n",
    "\n",
    "Our goal is to have a model read a short passage and a question, then **write the answer**. SQuAD was designed with answers that appear in the passage, but here we treat it as a tiny generation task: read the passage and question, then produce the answer text. This keeps the approach consistent across models and makes evaluation straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1415cb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "squad = load_dataset('squad')\n",
    "squad\n",
    "\n",
    "squad_train = squad['train'].shuffle()\n",
    "squad_validation = squad['validation'].shuffle()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f86e8f",
   "metadata": {},
   "source": [
    "Take a minute to skim a few SQuAD items. Notice where the answer lives in the passage and how long answers tend to be. Also watch for near‑miss phrases that could fool a word‑matching system. Make a quick guess for a safe upper bound on answer length—we’ll verify it next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "640dda51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"573173d8497a881900248f0c\",\n",
      "  \"title\": \"Egypt\",\n",
      "  \"context\": \"The Pew Forum on Religion & Public Life ranks Egypt as the fifth worst country in the world for religious freedom. The United States Commission on International Religious Freedom, a bipartisan independent agency of the US government, has placed Egypt on its watch list of countries that require close monitoring due to the nature and extent of violations of religious freedom engaged in or tolerated by the government. According to a 2010 Pew Global Attitudes survey, 84% of Egyptians polled supported the death penalty for those who leave Islam; 77% supported whippings and cutting off of hands for theft and robbery; and 82% support stoning a person who commits adultery.\",\n",
      "  \"question\": \"What percentage of Egyptians polled support death penalty for those leaving Islam?\",\n",
      "  \"answers\": {\n",
      "    \"text\": [\n",
      "      \"84%\"\n",
      "    ],\n",
      "    \"answer_start\": [\n",
      "      468\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"id\": \"57277e815951b619008f8b52\",\n",
      "  \"title\": \"Ann_Arbor,_Michigan\",\n",
      "  \"context\": \"The Ann Arbor Hands-On Museum is located in a renovated and expanded historic downtown fire station. Multiple art galleries exist in the city, notably in the downtown area and around the University of Michigan campus. Aside from a large restaurant scene in the Main Street, South State Street, and South University Avenue areas, Ann Arbor ranks first among U.S. cities in the number of booksellers and books sold per capita. The Ann Arbor District Library maintains four branch outlets in addition to its main downtown building. The city is also home to the Gerald R. Ford Presidential Library.\",\n",
      "  \"question\": \"Ann Arbor ranks 1st among what goods sold?\",\n",
      "  \"answers\": {\n",
      "    \"text\": [\n",
      "      \"books\"\n",
      "    ],\n",
      "    \"answer_start\": [\n",
      "      402\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"id\": \"572fc78d04bcaa1900d76d0a\",\n",
      "  \"title\": \"Scottish_Parliament\",\n",
      "  \"context\": \"Committees comprise a small number of MSPs, with membership reflecting the balance of parties across Parliament. There are different committees with their functions set out in different ways. Mandatory Committees are committees which are set down under the Scottish Parliament's standing orders, which govern their remits and proceedings. The current Mandatory Committees in the fourth Session of the Scottish Parliament are: Public Audit; Equal Opportunities; European and External Relations; Finance; Public Petitions; Standards, Procedures and Public Appointments; and Delegated Powers and Law Reform.\",\n",
      "  \"question\": \"What type of committee is set down under the SP's standing orders?\",\n",
      "  \"answers\": {\n",
      "    \"text\": [\n",
      "      \"Mandatory\",\n",
      "      \"Mandatory\",\n",
      "      \"Mandatory Committees\"\n",
      "    ],\n",
      "    \"answer_start\": [\n",
      "      192,\n",
      "      192,\n",
      "      192\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"id\": \"572ffd75b2c2fd14005686e8\",\n",
      "  \"title\": \"Rhine\",\n",
      "  \"context\": \"The last glacial ran from ~74,000 (BP = Before Present), until the end of the Pleistocene (~11,600 BP). In northwest Europe, it saw two very cold phases, peaking around 70,000 BP and around 29,000–24,000 BP. The last phase slightly predates the global last ice age maximum (Last Glacial Maximum). During this time, the lower Rhine flowed roughly west through the Netherlands and extended to the southwest, through the English Channel and finally, to the Atlantic Ocean. The English Channel, the Irish Channel and most of the North Sea were dry land, mainly because sea level was approximately 120 m (390 ft) lower than today.\",\n",
      "  \"question\": \"How much lower was the North Sea in the last cold phase than it is today?\",\n",
      "  \"answers\": {\n",
      "    \"text\": [\n",
      "      \"120 m\",\n",
      "      \"120 m\",\n",
      "      \"120 m\"\n",
      "    ],\n",
      "    \"answer_start\": [\n",
      "      593,\n",
      "      593,\n",
      "      593\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "peek(squad_train)\n",
    "peek(squad_validation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce4c366",
   "metadata": {},
   "source": [
    "Before generating anything, we’ll look at tokenized length distributions for inputs and answers. Choosing caps around the upper part of the distribution (roughly the 90th–95th percentile) strikes a balance: long enough not to cut off real answers, short enough to keep memory and runtime predictable. If answers get truncated, scores will sink even when the model “knows” the right span—so this step matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f0bf86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "T5 — source lengths percentiles: {50: 180, 75: 227, 90: 289, 95: 333, 99: 431}\n",
      "T5 — target lengths percentiles: {50: 4, 75: 7, 90: 11, 95: 16, 99: 28}\n",
      "\n",
      "GPT-2 — source lengths percentiles: {50: 162, 75: 204, 90: 258, 95: 296, 99: 388}\n",
      "GPT-2 — target lengths percentiles: {50: 3, 75: 5, 90: 9, 95: 13, 99: 25}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "# Choose tokenizers\n",
    "t5_name = 't5-base'              # good for text-to-text demos\n",
    "gpt2_name = 'gpt2-medium'                # medium GPT-2\n",
    "\n",
    "t5_tok = AutoTokenizer.from_pretrained(t5_name)\n",
    "gpt2_tok = AutoTokenizer.from_pretrained(gpt2_name)\n",
    "\n",
    "def qa_lengths(ds: Dataset, tokenizer, max_rows: int = 5000):\n",
    "    rows = min(len(ds), max_rows)\n",
    "    src_lens, tgt_lens = [], []\n",
    "    for i in range(rows):\n",
    "        ex = ds[i]\n",
    "        src_text = f\"question: {ex['question'].strip()}  context: {ex['context'].strip()}\"\n",
    "        tgt_text = ex['answers']['text'][0] if len(ex['answers']['text']) else ''\n",
    "        src_lens.append(len(tokenizer(src_text).input_ids))\n",
    "        tgt_lens.append(len(tokenizer(tgt_text).input_ids))\n",
    "    return np.array(src_lens), np.array(tgt_lens)\n",
    "\n",
    "src_lens_t5, tgt_lens_t5 = qa_lengths(squad_train, t5_tok, max_rows=20000)\n",
    "src_lens_g2, tgt_lens_g2 = qa_lengths(squad_train, gpt2_tok, max_rows=20000)\n",
    "\n",
    "def summarize_lens(name, src, tgt):\n",
    "    def pct(a): \n",
    "        return {p:int(np.percentile(a,p)) for p in [50,75,90,95,99]}\n",
    "    print(f\"\\n{name} — source lengths percentiles:\", pct(src))\n",
    "    print(f\"{name} — target lengths percentiles:\", pct(tgt))\n",
    "\n",
    "summarize_lens('T5', src_lens_t5, tgt_lens_t5)\n",
    "summarize_lens('GPT-2', src_lens_g2, tgt_lens_g2)\n",
    "\n",
    "# Plot (optional)\n",
    "plt.figure()\n",
    "plt.hist(src_lens_t5, bins=50)\n",
    "plt.title('T5 tokenized source length (question+context)')\n",
    "plt.xlabel('tokens'); plt.ylabel('count')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(tgt_lens_t5, bins=50)\n",
    "plt.title('T5 tokenized target length (answer)')\n",
    "plt.xlabel('tokens'); plt.ylabel('count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ecb1f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_SOURCE_QA = 512\n",
      "MAX_TARGET_QA = 32\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Based on the printed percentiles above, set conservative defaults.\n",
    "# If you have a smaller GPU, reduce these (e.g., source 384).\n",
    "\n",
    "MAX_SOURCE_QA = 512    # Source (question+context) tokens\n",
    "MAX_TARGET_QA = 32     # Answers in SQuAD are short; 32 tokens is typically ample\n",
    "\n",
    "print('MAX_SOURCE_QA =', MAX_SOURCE_QA)\n",
    "print('MAX_TARGET_QA =', MAX_TARGET_QA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f670b8",
   "metadata": {},
   "source": [
    "We’ll work with a modest SQuAD subset so everything runs smoothly on shared hardware. That’s perfect for learning the workflow and comparing strategies. Treat absolute numbers as illustrative; the *direction* of change is the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "741f615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_train = squad_train.select(range(10000))\n",
    "qa_validation = squad_train.select(range(10000, 11000))\n",
    "qa_test = squad_validation.select(range(2000))\n",
    "\n",
    "# cleaning unused data\n",
    "del squad\n",
    "del squad_train\n",
    "del squad_validation\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53057ed8",
   "metadata": {},
   "source": [
    "**What the next helpers do.** These wrappers run generation over a batch of prompts with safe defaults. One is written for encoder–decoder models like T5; the other is for decoder‑only models like GPT‑2. Both enforce our length limits and make it easy to switch between greedy decoding and a small beam without touching the lower‑level details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcc36ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "@torch.no_grad()\n",
    "def seq2seq_inference(model, tokenizer, prompts, batch_size=32, max_length=512, max_new_tokens=64):\n",
    "    \"\"\"\n",
    "    Sequence-to-sequence inference function for encoder-decoder models.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.config.use_cache = True\n",
    "    device = next(model.parameters()).device\n",
    "    preds = []\n",
    "\n",
    "    for i in tqdm.tqdm(range(0, len(prompts), batch_size)):\n",
    "        batch = prompts[i:i+batch_size]\n",
    "        enc = tokenizer(batch, return_tensors='pt', padding=True, truncation=True,\n",
    "                        pad_to_multiple_of=8, max_length=max_length).to(device)\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            out = model.generate(\n",
    "                **enc,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                do_sample=False,\n",
    "                use_cache=True,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                pad_token_id=tokenizer.pad_token_id or tokenizer.eos_token_id,\n",
    "                return_dict_in_generate=False\n",
    "            )\n",
    "        preds.extend(tokenizer.batch_decode(out, skip_special_tokens=True))\n",
    "    return preds\n",
    "\n",
    "@torch.no_grad()\n",
    "def clm_inference(model, tokenizer, prompts, batch_size=32, max_length=512, max_new_tokens=64):\n",
    "    \"\"\"\n",
    "    Inference function for decoder-only models (causal language models).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.config.use_cache = True           # KV cache\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"left\"         # best for decoder-only generation\n",
    "    device = next(model.parameters()).device\n",
    "    preds = []\n",
    "\n",
    "    for i in tqdm.tqdm(range(0, len(prompts), batch_size)):\n",
    "        batch = prompts[i:i+batch_size]\n",
    "        enc = tokenizer(\n",
    "            batch, return_tensors=\"pt\",\n",
    "            padding=True, pad_to_multiple_of=8,   # tensor-core friendly\n",
    "            truncation=True, max_length=max_length\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            out = model.generate(\n",
    "                **enc,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                do_sample=False,\n",
    "                use_cache=True,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                pad_token_id=tokenizer.pad_token_id or tokenizer.eos_token_id,\n",
    "                return_dict_in_generate=False\n",
    "            )\n",
    "\n",
    "        # slice off the prompt to keep only newly generated tokens\n",
    "        gen_only = out[:, enc[\"input_ids\"].shape[1]:]\n",
    "        texts = tokenizer.batch_decode(gen_only, skip_special_tokens=True)\n",
    "        preds.extend([t.strip() for t in texts])\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b661e2",
   "metadata": {},
   "source": [
    "Once the tokenizer do its job, we can read the outputs of the models and check their answers!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15ee99c",
   "metadata": {},
   "source": [
    "When we decode model outputs back to text, we strip any echoed prompt and keep only the answer. The evaluation scripts compare clean strings, so keeping outputs tidy is worth the small effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c76ac36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Paris'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5 = AutoModelForSeq2SeqLM.from_pretrained(t5_name).to(device)\n",
    "answers = seq2seq_inference(t5, t5_tok, [\"question: What was the capital of France in 1950?  context: France is a country in Europe.\"])\n",
    "answers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4645ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we should clean the memory after we finished using the model\n",
    "del t5\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad9518c",
   "metadata": {},
   "source": [
    "For the SQUAD dataset, we will be meassuring performance using two metrics:\n",
    "\n",
    "**Exact Match (EM)** - This strict metric assigns a score of 1 if the model’s prediction matches one of the ground-truth answers exactly after normalising case and punctuation, and 0 otherwise. Even a single character difference leads to a score of 0.\n",
    "\n",
    "**F1 Score** - This is the harmonic mean of precision and recall over the tokens in the predicted and reference answers. F1 rewards partial overlap; it ranges from 0 (no overlap) to 1 (perfect match).\n",
    "\n",
    "*Example.* Suppose the reference answers are `[\"water\", \"water bodies\"]` and the model predicts `\"water\"`. The prediction matches one reference exactly, so EM = 1. Token overlap with \"water bodies\" yields precision = 1/1 and recall = 1/2, giving F1 = 2×(1/1×1/2)/(1/1+1/2)=0.67."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c7acad",
   "metadata": {},
   "source": [
    "We’ll use the SQuAD scorer provided through the `evaluate` library. It implements the canonical script used in the literature, including the usual text normalization, so our numbers are comparable and sensible out of the box.\n",
    "\n",
    "Note: We only take the first answer as the expected answer for simplicity. Some answer lists are repeated, but in reality, there might be more than a possible answer for a question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea3ec06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_metric = evaluate.load('squad')\n",
    "def evaluate_qa(predictions, references):\n",
    "    \"\"\"Format predictions and references for the SQuAD metric.\n",
    "\n",
    "    Supports references provided as:\n",
    "    - list of strings (multiple gold answers)\n",
    "    - dict with keys 'text' and 'answer_start'\n",
    "    - dict with key 'answers' containing the above\n",
    "    - single string\n",
    "    \"\"\"\n",
    "    formatted_preds = [{\"id\": str(i), \"prediction_text\": p} for i, p in enumerate(predictions)]\n",
    "    formatted_refs = []\n",
    "    for i, ref in enumerate(references):\n",
    "        if isinstance(ref, dict) and \"answers\" in ref:\n",
    "            answers = ref[\"answers\"]\n",
    "        elif isinstance(ref, dict) and (\"text\" in ref and \"answer_start\" in ref):\n",
    "            answers = ref\n",
    "        elif isinstance(ref, str):\n",
    "            answers = {\"text\": [ref], \"answer_start\": [0]}\n",
    "        else:\n",
    "            # assume iterable of strings\n",
    "            texts = list(ref)\n",
    "            answers = {\"text\": texts, \"answer_start\": [0] * len(texts)}\n",
    "            \n",
    "        formatted_refs.append({\"id\": str(i), \"answers\": answers})\n",
    "    return squad_metric.compute(predictions=formatted_preds, references=formatted_refs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064f5e38",
   "metadata": {},
   "source": [
    "### Exercise: Let's try QA prompting!\n",
    "\n",
    "Now that we can generate answers and evaluate them, let’s try a couple of prompt wordings and decoding settings. Keep the format stable and change just one thing at a time so differences are meaningful.\n",
    "\n",
    "Add at least one new entry to the `qa_prompt_strategies` dictionary. We challenge you to beat the *minimal* strategy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80480c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt_strategies = {\n",
    "    'minimal': lambda question, context: f\"question: {question} context: {context} answer:\",\n",
    "    'instruction': lambda question, context: f'Given the context:\\n\\n\"{context}\"\\n\\nAnswer the following question:\\n\\n\"{question}\"\\nAnswer:',\n",
    "    # Add your own strategies here.\n",
    "}\n",
    "\n",
    "def apply_qa_prompt_strategy(strategy_name, dataset) -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Apply the specified prompt strategy to the dataset.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the list of prompts and the list of reference answers.\n",
    "    \"\"\"\n",
    "    if strategy_name in qa_prompt_strategies:\n",
    "        prompt_func = qa_prompt_strategies[strategy_name]\n",
    "        prompts = [prompt_func(sample['question'], sample['context']) for sample in dataset]\n",
    "        references = [sample['answers']['text'] for sample in dataset]\n",
    "        return prompts, references\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown prompt strategy: {strategy_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f7466b",
   "metadata": {},
   "source": [
    "You can test visually some answers with the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe6a6f05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== strategy 'minimal' with T5 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 'question: Along with anxiety, what is an example of directionless emotion? context: The word \"emotion\" dates back to 1579, when it was adapted from the French word émouvoir, which means \"to stir up\". The term emotion was introduced into academic discussion to replace passion. According to one dictionary, the earliest precursors of the word likely dates back to the very origins of language. The modern word emotion is heterogeneous In some uses of the word, emotions are intense feelings that are directed at someone or something. On the other hand, emotion can be used to refer to states that are mild (as in annoyed or content) and to states that are not directed at anything (as in anxiety and depression). One line of research thus looks at the meaning of the word emotion in everyday language and this usage is rather different from that in academic discourse. Another line of research asks about languages other than English, and one interesting finding is that many languages have a similar but not identical term answer:'\n",
      "Prediction: 'depression'\n",
      "Reference: '['depression']'\n",
      "Prompt: 'question: Who became the top PC manufacturer in 1994, leaving Apple in 3rd place? context: The Macintosh, however, was expensive, which hindered its ability to be competitive in a market already dominated by the Commodore 64 for consumers, as well as the IBM Personal Computer and its accompanying clone market for businesses. Macintosh systems still found success in education and desktop publishing and kept Apple as the second-largest PC manufacturer for the next decade. In the 1990s, improvements in the rival Wintel platform, notably with the introduction of Windows 3.0, then Windows 95, gradually took market share from the more expensive Macintosh systems. The performance advantage of 68000-based Macintosh systems was eroded by Intel's Pentium, and in 1994 Apple was relegated to third place as Compaq became the top PC manufacturer. Even after a transition to the superior PowerPC-based Power Macintosh (later renamed the PowerMac, in line with the PowerBook series) line in 1994, the falling prices of commodity PC components and the release of Windows 95 saw the Macintosh user base decline. answer:'\n",
      "Prediction: 'Compaq'\n",
      "Reference: '['Compaq']'\n",
      "-> EM: 100.0 F1: 100.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== strategy 'minimal' with GPT-2 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 'question: Along with anxiety, what is an example of directionless emotion? context: The word \"emotion\" dates back to 1579, when it was adapted from the French word émouvoir, which means \"to stir up\". The term emotion was introduced into academic discussion to replace passion. According to one dictionary, the earliest precursors of the word likely dates back to the very origins of language. The modern word emotion is heterogeneous In some uses of the word, emotions are intense feelings that are directed at someone or something. On the other hand, emotion can be used to refer to states that are mild (as in annoyed or content) and to states that are not directed at anything (as in anxiety and depression). One line of research thus looks at the meaning of the word emotion in everyday language and this usage is rather different from that in academic discourse. Another line of research asks about languages other than English, and one interesting finding is that many languages have a similar but not identical term answer:'\n",
      "Prediction: '\"emotion\" is used in many languages to refer to a state of mind, but it is not used to refer to a state of mind. For example, in the language of the United States, the word \"emotion\" is used to refer to a state of mind, but it is not used to refer'\n",
      "Reference: '['depression']'\n",
      "Prompt: 'question: Who became the top PC manufacturer in 1994, leaving Apple in 3rd place? context: The Macintosh, however, was expensive, which hindered its ability to be competitive in a market already dominated by the Commodore 64 for consumers, as well as the IBM Personal Computer and its accompanying clone market for businesses. Macintosh systems still found success in education and desktop publishing and kept Apple as the second-largest PC manufacturer for the next decade. In the 1990s, improvements in the rival Wintel platform, notably with the introduction of Windows 3.0, then Windows 95, gradually took market share from the more expensive Macintosh systems. The performance advantage of 68000-based Macintosh systems was eroded by Intel's Pentium, and in 1994 Apple was relegated to third place as Compaq became the top PC manufacturer. Even after a transition to the superior PowerPC-based Power Macintosh (later renamed the PowerMac, in line with the PowerBook series) line in 1994, the falling prices of commodity PC components and the release of Windows 95 saw the Macintosh user base decline. answer:'\n",
      "Prediction: 'Apple's performance advantage over the competition was eroded by the introduction of Windows 95, which was a major upgrade to the operating system. The introduction of Windows 95 also saw the introduction of the Macintosh's first 64-bit processor, the PowerPC G4, which was a significant upgrade over the G3. The introduction of'\n",
      "Reference: '['Compaq']'\n",
      "-> EM: 0.0 F1: 0.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = qa_validation.select(range(2))\n",
    "\n",
    "STRATEGY = \"minimal\"\n",
    "\n",
    "# Uncomment to test t5\n",
    "t5 = AutoModelForSeq2SeqLM.from_pretrained(t5_name).to(device)\n",
    "t5_tok = AutoTokenizer.from_pretrained(t5_name)\n",
    "\n",
    "print(f\"== strategy '{STRATEGY}' with T5 ==\")\n",
    "prompts, references = apply_qa_prompt_strategy(STRATEGY, dataset)\n",
    "predictions = seq2seq_inference(t5, t5_tok, prompts)\n",
    "\n",
    "for prompt, prediction, reference in zip(prompts, predictions, references):\n",
    "    print(f\"Prompt: '{prompt}'\")\n",
    "    print(f\"Prediction: '{prediction}'\")\n",
    "    print(f\"Reference: '{reference}'\",)\n",
    "\n",
    "scores = evaluate_qa(predictions, references)\n",
    "print(f\"-> EM: {scores['exact_match']} F1: {scores['f1']}\", end='\\n\\n')\n",
    "\n",
    "del t5, t5_tok\n",
    "clear_memory()\n",
    "\n",
    "# Uncomment to test GPT-2\n",
    "gpt2 = AutoModelForCausalLM.from_pretrained(gpt2_name).to(device)\n",
    "gpt2_tok = AutoTokenizer.from_pretrained(gpt2_name)\n",
    "\n",
    "print(f\"== strategy '{STRATEGY}' with GPT-2 ==\")\n",
    "prompts, references = apply_qa_prompt_strategy(STRATEGY, dataset)\n",
    "predictions = clm_inference(gpt2, gpt2_tok, prompts)\n",
    "\n",
    "for prompt, prediction, reference in zip(prompts, predictions, references):\n",
    "    print(f\"Prompt: '{prompt}'\")\n",
    "    print(f\"Prediction: '{prediction}'\")\n",
    "    print(f\"Reference: '{reference}'\")\n",
    "\n",
    "scores = evaluate_qa(predictions, references)\n",
    "print(f\"-> EM: {scores['exact_match']} F1: {scores['f1']}\", end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6e6e45",
   "metadata": {},
   "source": [
    "Add your strategy, then run the cell below to evaluate all defined strategies on the validation set. Skim a few outputs to see what the model is doing—do names and numbers survive the trip into the target language?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aea9473c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=   Evaluating T5   =\n",
      "== strategy 'minimal' ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:07<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> EM: 57.3 F1: 63.72726161519638\n",
      "\n",
      "== strategy 'instruction' ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:07<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> EM: 0.2 F1: 0.2168929110105581\n",
      "\n",
      "\n",
      "=   Evaluating GPT-2   =\n",
      "== strategy 'minimal' ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:37<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> EM: 0.0 F1: 5.165764101120821\n",
      "\n",
      "== strategy 'instruction' ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:38<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> EM: 0.0 F1: 6.418160333476867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = qa_validation\n",
    "\n",
    "print(\"=   Evaluating T5   =\")\n",
    "t5 = AutoModelForSeq2SeqLM.from_pretrained(t5_name).to(device)\n",
    "t5_tok = AutoTokenizer.from_pretrained(t5_name)\n",
    "for strategy_name in qa_prompt_strategies.keys():\n",
    "    print(f\"== strategy '{strategy_name}' ==\")\n",
    "    prompts, references = apply_qa_prompt_strategy(strategy_name, dataset)\n",
    "    predictions = seq2seq_inference(t5, t5_tok, prompts, batch_size=64)\n",
    "    scores = evaluate_qa(predictions, references)\n",
    "    print(f\"-> EM: {scores['exact_match']} F1: {scores['f1']}\", end='\\n\\n')\n",
    "\n",
    "del t5\n",
    "clear_memory()\n",
    "\n",
    "print(\"\\n=   Evaluating GPT-2   =\")\n",
    "gpt2 = AutoModelForCausalLM.from_pretrained(gpt2_name).to(device)\n",
    "gpt2_tok = AutoTokenizer.from_pretrained(gpt2_name)\n",
    "for strategy_name in qa_prompt_strategies.keys():\n",
    "    print(f\"== strategy '{strategy_name}' ==\")\n",
    "    prompts, references = apply_qa_prompt_strategy(strategy_name, dataset)\n",
    "    predictions = clm_inference(gpt2, gpt2_tok, prompts, batch_size=64)\n",
    "    scores = evaluate_qa(predictions, references)\n",
    "    print(f\"-> EM: {scores['exact_match']} F1: {scores['f1']}\", end='\\n\\n')\n",
    "\n",
    "del gpt2\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42af7271",
   "metadata": {},
   "source": [
    "Pick your best strategy and run it on the **test split**. Keep the prompt text handy—we’ll reuse the same format after fine‑tuning so our comparison stays fair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb3a3282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=   Evaluating T5 with strategy minimal on Test! =\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:14<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> EM: 59.4 F1: 63.12455129894259\n",
      "\n",
      "=   Evaluating GPT-2 with strategy minimal on Test! =\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [01:23<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> EM: 0.0 F1: 5.70529276410452\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = qa_test\n",
    "BEST_STRATEGY = 'minimal'\n",
    "\n",
    "print(f\"=   Evaluating T5 with strategy {BEST_STRATEGY} on Test! =\")\n",
    "t5 = AutoModelForSeq2SeqLM.from_pretrained(t5_name).to(device)\n",
    "t5_tok = AutoTokenizer.from_pretrained(t5_name)\n",
    "prompts, references = apply_qa_prompt_strategy(BEST_STRATEGY, dataset)\n",
    "predictions = seq2seq_inference(t5, t5_tok, prompts, batch_size=64)\n",
    "scores = evaluate_qa(predictions, references)\n",
    "print(f\"-> EM: {scores['exact_match']} F1: {scores['f1']}\", end='\\n\\n')\n",
    "\n",
    "del t5\n",
    "clear_memory()\n",
    "\n",
    "print(f\"=   Evaluating GPT-2 with strategy {BEST_STRATEGY} on Test! =\")\n",
    "gpt2 = AutoModelForCausalLM.from_pretrained(gpt2_name).to(device)\n",
    "gpt2_tok = AutoTokenizer.from_pretrained(gpt2_name)\n",
    "prompts, references = apply_qa_prompt_strategy(BEST_STRATEGY, dataset)\n",
    "predictions = clm_inference(gpt2, gpt2_tok, prompts, batch_size=64)\n",
    "scores = evaluate_qa(predictions, references)\n",
    "print(f\"-> EM: {scores['exact_match']} F1: {scores['f1']}\", end='\\n\\n')\n",
    "\n",
    "del gpt2\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bc085d",
   "metadata": {},
   "source": [
    "It is not a coincidence that minimal got a good performance for **T5** out of the box. The **T5** model was trained on many instructions and NLP tasks, like Question Answering (although not specifically in SQUAD). It seems this prompting strategy is very much present in its base training. \n",
    "\n",
    "Short, well‑labeled prompts often work nicely with encoder–decoder models like **T5**, which read the input fully and write a concise output. Decoder‑only models can also do well here, but they often benefit more from a short, targeted fine‑tuning step on the task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfd8063",
   "metadata": {},
   "source": [
    "### Fine-tuning GPT-2\n",
    "\n",
    "Fine-tuning an LLM is the process of teaching it on an specific task. This is usually done for preparing an LLM to perform well on a downstream task. The process is very much alike the one for pretraining them, albeit with a much smaller dataset. This means that the model is going to get biased to the specific task, and many times we will see its performance decreasing on other tasks. This phenomenon is called Catastrofic Forgetting, and still have no known cure. We will discuss this a bit more later in the session.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1326507",
   "metadata": {},
   "source": [
    "Fine‑tuning means taking a general model and nudging it toward our task with labeled examples. We keep the same prompt style—context and question followed by “Answer:” —and train the model so that the part it learns to write is just the answer text. This focuses learning on what matters and keeps inference simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9739311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer, SFTConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4593e39c",
   "metadata": {},
   "source": [
    "To fine‑tune GPT‑2, we first prepare the tokenizer and preprocess the data properly. We build prompt‑answer pairs and set the tokenizer to pad on the right. This ensures the model sees the prompt and answer in the correct order and that batches align neatly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6d8655c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gpt2_tok = AutoTokenizer.from_pretrained(gpt2_name)\n",
    "gpt2_tok.padding_side = \"right\"\n",
    "gpt2_tok.pad_token = gpt2_tok.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca9ac57",
   "metadata": {},
   "source": [
    "Then, we prepare the data for ingesting to the training loop.\n",
    "\n",
    "For `SFTTrainer` to work, we need to properly separate prompts and completions (being completions our expected answers to questions). We apply the function to both training and validation datasets and filter out any with an empty completion to avoid errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da88dc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- make a prompt-completion view of SQuAD ---\n",
    "def to_prompt_completion(batch):\n",
    "    prompts, completions = [], []\n",
    "    for q, c, a in zip(batch[\"question\"], batch[\"context\"], batch[\"answers\"]):\n",
    "        gold = a[\"text\"][0] if a[\"text\"] else \"\"\n",
    "        if not gold.strip():          # filter empties (prevents labelless samples)\n",
    "            gold = \"\"                 # keep or skip; we skip below\n",
    "            \n",
    "        prompts.append(f\"question: {q} context: {c}\")\n",
    "        completions.append(\" \" + gold)\n",
    "    return {\"prompt\": prompts, \"completion\": completions}\n",
    "\n",
    "train_pc = qa_train.map(\n",
    "    to_prompt_completion, batched=True,\n",
    "    remove_columns=qa_train.column_names,\n",
    "    desc=\"Building prompt-completion (train)\"\n",
    ")\n",
    "valid_pc = qa_validation.map(\n",
    "    to_prompt_completion, batched=True,\n",
    "    remove_columns=qa_validation.column_names,\n",
    "    desc=\"Building prompt-completion (valid)\"\n",
    ")\n",
    "\n",
    "# Filter truly empty completions (no supervised tokens)\n",
    "def nonempty(ex): return len(ex[\"completion\"].strip()) > 0\n",
    "train_pc = train_pc.filter(nonempty, desc=\"Filter empty completions (train)\")\n",
    "valid_pc = valid_pc.filter(nonempty, desc=\"Filter empty completions (valid)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ad714a",
   "metadata": {},
   "source": [
    "But why do we need to have prompts and completions separated?\n",
    "\n",
    "When we train in Causal Language Modelling, the trainer basically takes the input tokens, shift them to the right by one position, and use them for evaluating the prediction capacity of the model. This prediction distribution is matched against the expected distribution by computing a loss function. \n",
    "\n",
    "However, how much of that distribution is our actual target? We saw that most of the input (question + context) were around 300 tokens, while the expected answer tokens were less than 10 in its majority. This means that if we compute the loss function with all the sequence, the input sequence will be dominating the loss computation and probably diminishing the gains from fine-tuning.\n",
    "\n",
    "In the code below, we set the training parameters, like the `batch size`, `learning rate`, and there is a `completion_only_loss` parameter that targets this specific problem, and it is already implemented!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc53627c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 50256}.\n",
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1252' max='1252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1252/1252 09:02, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Num Tokens</th>\n",
       "      <th>Mean Token Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.842100</td>\n",
       "      <td>0.709239</td>\n",
       "      <td>2.556895</td>\n",
       "      <td>1139695.000000</td>\n",
       "      <td>0.828394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.613200</td>\n",
       "      <td>0.618537</td>\n",
       "      <td>2.494343</td>\n",
       "      <td>2312402.000000</td>\n",
       "      <td>0.843151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.542100</td>\n",
       "      <td>0.579403</td>\n",
       "      <td>2.420723</td>\n",
       "      <td>3458994.000000</td>\n",
       "      <td>0.850641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.509800</td>\n",
       "      <td>0.558452</td>\n",
       "      <td>2.294940</td>\n",
       "      <td>4610184.000000</td>\n",
       "      <td>0.856891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.439100</td>\n",
       "      <td>0.563348</td>\n",
       "      <td>2.245056</td>\n",
       "      <td>5751667.000000</td>\n",
       "      <td>0.856759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.437200</td>\n",
       "      <td>0.556084</td>\n",
       "      <td>2.258068</td>\n",
       "      <td>6890743.000000</td>\n",
       "      <td>0.854903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1252, training_loss=0.6525307459572253, metrics={'train_runtime': 544.8684, 'train_samples_per_second': 73.412, 'train_steps_per_second': 2.298, 'total_flos': 1.3563644621684736e+16, 'train_loss': 0.6525307459572253, 'entropy': 2.385621428489685, 'num_tokens': 7152692.0, 'mean_token_accuracy': 0.9049517214298248, 'epoch': 4.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = SFTConfig(\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=1e-5,\n",
    "    max_grad_norm=1.0,\n",
    "    seed=SEED,\n",
    "\n",
    "    # Efficiency\n",
    "    group_by_length=True,       # minimize padding in each batch\n",
    "\n",
    "    # Precision / memory\n",
    "    gradient_checkpointing=True,\n",
    "\n",
    "    # Forward to from_pretrained (disable cache during training)\n",
    "    model_init_kwargs={\"use_cache\": False},\n",
    "\n",
    "    # make completion-only explicit; it’s default for prompt-completion\n",
    "    completion_only_loss=True,\n",
    "\n",
    "    # Logging & eval\n",
    "    report_to=[],\n",
    "    run_name=None,\n",
    "    logging_strategy=\"steps\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=400,\n",
    "    save_total_limit=1,             # keep only {best, most recent}\n",
    "    load_best_model_at_end=True    # after training, load the best checkpoint\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=gpt2_name,\n",
    "    args=cfg,\n",
    "    train_dataset=train_pc,          # expects columns: \"prompt\", \"completion\"\n",
    "    eval_dataset=valid_pc,\n",
    "    processing_class=gpt2_tok,            # <-- pass tokenizer here\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef628097",
   "metadata": {},
   "source": [
    "Now, lets see if this tuned model really learned something"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04d74ab",
   "metadata": {},
   "source": [
    "### After training\n",
    "\n",
    "Run the same evaluation as before. If EM and F1 improved, open a few examples to see how. Do answers look more concise? Are fewer getting cut off? Keep one or two before/after examples—we’ll revisit them in the wrap‑up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46431c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=   Evaluating fine-tuned GPT-2 with strategy 'minimal' on Test! =\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:36<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> EM: 58.55 F1: 67.71997057461992\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"=   Evaluating fine-tuned GPT-2 with strategy '{BEST_STRATEGY}' on Test! =\")\n",
    "gpt2 = trainer.model.eval()\n",
    "gpt2_tok = trainer.processing_class\n",
    "prompts, references = apply_qa_prompt_strategy(BEST_STRATEGY, dataset)\n",
    "predictions = clm_inference(gpt2, gpt2_tok, prompts)\n",
    "scores = evaluate_qa(predictions, references)\n",
    "print(f\"-> EM: {scores['exact_match']} F1: {scores['f1']}\", end='\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc04dec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainer\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6bc749",
   "metadata": {},
   "source": [
    "Great, it seems **GPT-2** now understand the task a lot better and improved its performance over 10 times! Now it is comparable to base **T5** with the prompting strategy 'minimal'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba38e6b4",
   "metadata": {},
   "source": [
    "We’ve now guided a general model with a clear prompt and tuned it so it answers questions more reliably. Let’s apply the same workflow to translation: start with a simple prompt, see what we get, and then fine‑tune a model to translate English to Spanish more consistently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028e38a9",
   "metadata": {},
   "source": [
    "# Part B — Machine Translation (English→Spanish on OPUS‑100)\n",
    "\n",
    "We now examine **machine translation** with **t5-base** and **GPT-2-medium** and see how these models behave in this task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97b3937",
   "metadata": {},
   "source": [
    "Let’s look at a few English–Spanish pairs to get a feel for length, tone, and named entities that must be preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02b1d184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4796d9e6c3a406fb55bfe5075b3043c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e6447eaa12473ab0db819ef3b9c9ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/237k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec559b5f521f4056a8c9c6d4c93b6ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/99.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352cadef7d1846e58019e3f736e532d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/238k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "822e9c34ed0f49a79ec428b11aa58c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a1090a9ee448caa24ca04175f2a312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1000000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f545c00349f94c4e82fbc228957de73d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "# Load OPUS-100 English-Spanish. The full dataset is large; we will sample for class runtime.\n",
    "opus = load_dataset('Helsinki-NLP/opus-100', 'en-es')\n",
    "opus\n",
    "\n",
    "opus_train = opus['train'].shuffle()\n",
    "opus_validation = opus['validation'].shuffle()\n",
    "opus_test = opus['test'].shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ab5448d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"translation\": {\n",
      "    \"en\": \"What measures exist to prevent their forgery etc?\",\n",
      "    \"es\": \"¿Qué medidas existen para evitar su falsificación, etc.?\"\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"translation\": {\n",
      "    \"en\": \"- Cries.\",\n",
      "    \"es\": \"- Gritos.\"\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"translation\": {\n",
      "    \"en\": \"If only we can get down to them.\",\n",
      "    \"es\": \"Si tan solo pudiéramos bajar.\"\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"translation\": {\n",
      "    \"en\": \"Okay, that bitch is dead.\",\n",
      "    \"es\": \"Okay, esa perra esta muerta.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "peek(opus_train)\n",
    "peek(opus_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedf0633",
   "metadata": {},
   "source": [
    "Translated sentences are naturally longer than short QA answers. We’ll repeat the length check for English sources and Spanish targets and set comfortable caps so we do not cut off translations. As before, aim for the upper part of the observed distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c313f662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "T5 source (en) lengths percentiles: {50: 9, 75: 16, 90: 31, 95: 43, 99: 71}\n",
      "T5 target (es) lengths percentiles: {50: 18, 75: 33, 90: 69, 95: 98, 99: 161}\n",
      "\n",
      "GPT-2 source (en) lengths percentiles: {50: 9, 75: 16, 90: 31, 95: 43, 99: 71}\n",
      "GPT-2 target (es) lengths percentiles: {50: 14, 75: 26, 90: 56, 95: 80, 99: 132}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "t5_name = 't5-base'              # good for text-to-text demos\n",
    "gpt2_name = 'gpt2-medium'                # medium GPT-2\n",
    "\n",
    "t5_tok = AutoTokenizer.from_pretrained(t5_name)\n",
    "gpt2_tok = AutoTokenizer.from_pretrained(gpt2_name)\n",
    "\n",
    "def mt_lengths(ds: Dataset, tokenizer, src_key='en', tgt_key='es', max_rows: int = 20000):\n",
    "    rows = min(len(ds), max_rows)\n",
    "    src_lens, tgt_lens = [], []\n",
    "    for i in range(rows):\n",
    "        ex = ds[i]['translation']\n",
    "        src_lens.append(len(tokenizer(ex[src_key]).input_ids))\n",
    "        tgt_lens.append(len(tokenizer(ex[tgt_key]).input_ids))\n",
    "    return np.array(src_lens), np.array(tgt_lens)\n",
    "\n",
    "src_l_mt_t5, tgt_l_mt_t5 = mt_lengths(opus_train, t5_tok, max_rows=20000)\n",
    "src_l_mt_gpt, tgt_l_mt_gpt = mt_lengths(opus_train, gpt2_tok, max_rows=20000)\n",
    "\n",
    "def summarize_lens(name, src, tgt):\n",
    "    def pct(a): \n",
    "        return {p:int(np.percentile(a,p)) for p in [50,75,90,95,99]}\n",
    "    print(f\"\\n{name} source (en) lengths percentiles:\", pct(src))\n",
    "    print(f\"{name} target (es) lengths percentiles:\", pct(tgt))\n",
    "\n",
    "summarize_lens('T5', src_l_mt_gpt, tgt_l_mt_t5)\n",
    "summarize_lens('GPT-2', src_l_mt_gpt, tgt_l_mt_gpt)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(src_l_mt_t5, bins=60)\n",
    "plt.title('T5 tokenized source length (English)')\n",
    "plt.xlabel('tokens'); plt.ylabel('count')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(tgt_l_mt_t5, bins=60)\n",
    "plt.title('T5 tokenized target length (Spanish)')\n",
    "plt.xlabel('tokens'); plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52759406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_SOURCE_MT = 128\n",
      "MAX_TARGET_MT = 256\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Based on the printed percentiles above, set conservative defaults.\n",
    "# If you have a smaller GPU, reduce these (e.g., source 384).\n",
    "\n",
    "MAX_SOURCE_MT = 128\n",
    "MAX_TARGET_MT = 256\n",
    "\n",
    "print('MAX_SOURCE_MT =', MAX_SOURCE_MT)\n",
    "print('MAX_TARGET_MT =', MAX_TARGET_MT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c14aff",
   "metadata": {},
   "source": [
    "Same as with SQUAD, we will work with subsets of OPUS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "627efaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_train = opus_train.select(range(60000))\n",
    "mt_validation = opus_validation.select(range(2000))\n",
    "mt_test = opus_test.select(range(2000))\n",
    "\n",
    "# cleaning unused data\n",
    "del opus\n",
    "del opus_train\n",
    "del opus_validation\n",
    "del opus_test\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7358450d",
   "metadata": {},
   "source": [
    "#### Evaluation for Translation\n",
    "\n",
    "For this session we evaluate QA on the BLEU metric:\n",
    "\n",
    "**BLEU** - bilingual evaluation understudy (BLEU) score. BLEU computes the geometric mean of modified n-gram precisions between a candidate and one or more reference translations, multiplied by a brevity penalty. Scores lie between 0 and 1, where values closer to 1 indicate closer correspondence to references.\n",
    "\n",
    "In this notebook, we’ll report **sacreBLEU**, a version of BLEU that standardizes tokenization so scores are comparable and reproducible.\n",
    "\n",
    "We will make use of the official metric implementations available in Huggingface Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "426747e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5474860959ef42dfab442fab5234da90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bleu_metric = evaluate.load('sacrebleu')\n",
    "\n",
    "def evaluate_bleu(predictions, references):\n",
    "    \"\"\"Evaluate BLEU score for translation tasks.\"\"\"\n",
    "    return bleu_metric.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f66a35f",
   "metadata": {},
   "source": [
    "### Translation Prompting\n",
    "\n",
    "Now, just like with Question Answering, we will see how we can use these models without any fine-tuning for Machine Translation. lets try different prompting strategies!\n",
    "\n",
    "Try adding some prompts to `mt_prompt_strategies` and see what performance you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b9dcacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_prompt_strategies = {\n",
    "    'minimal': lambda en_source: f\"English: {en_source} Spanish:\",\n",
    "    'minimal_instruction': lambda en_source: f\"Translate English to Spanish: {en_source}\",\n",
    "    'instruction': lambda en_source: f'Translate English to Spanish: {en_source}\\nTranslation:',\n",
    "    # Add your own strategies here.\n",
    "}\n",
    "\n",
    "def apply_mt_prompt_strategy(strategy_name, dataset) -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Apply the specified prompt strategy to the dataset.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the list of prompts and the list of reference answers.\n",
    "    \"\"\"\n",
    "    if strategy_name in mt_prompt_strategies:\n",
    "        prompt_func = mt_prompt_strategies[strategy_name]\n",
    "        prompts = [prompt_func(sample['translation']['en']) for sample in dataset]\n",
    "        references = [sample['translation']['es'] for sample in dataset]\n",
    "        return prompts, references\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown prompt strategy: {strategy_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4404b99",
   "metadata": {},
   "source": [
    "Test your prompts visually with the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1debcdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== strategy 'minimal' with T5 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 'English: If only we can get down to them. Spanish:'\n",
      "Prediction: 'Wenn wir nur auf sie zugehen können.'\n",
      "Reference: 'Si tan solo pudiéramos bajar.'\n",
      "Prompt: 'English: Okay, that bitch is dead. Spanish:'\n",
      "Prediction: 'Okay, that bitch is dead.'\n",
      "Reference: 'Okay, esa perra esta muerta.'\n",
      "-> BLEU: 7.1338676779176575\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== strategy 'minimal' with GPT-2 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 'English: If only we can get down to them. Spanish:'\n",
      "Prediction: 'Español\n",
      "\n",
      "Finnish: Päätä (fi)\n",
      "\n",
      "French: Père (fr)\n",
      "\n",
      "German: Pfeil (de)\n",
      "\n",
      "Italian: Piazza (it)\n",
      "\n",
      "Polish: Příż (pl)\n",
      "\n",
      "Port'\n",
      "Reference: 'Si tan solo pudiéramos bajar.'\n",
      "Prompt: 'English: Okay, that bitch is dead. Spanish:'\n",
      "Prediction: 'I'm sorry.\n",
      "\n",
      "In the episode \"The Man Who Wasn't There\", the character of the character of the character of the character of the character of the character of the character of the character of the character of the character of the character of the character of the character of the character of the character of the'\n",
      "Reference: 'Okay, esa perra esta muerta.'\n",
      "-> BLEU: 0.47256291889095237\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = mt_validation.select(range(2))\n",
    "\n",
    "STRATEGY = \"minimal\"\n",
    "\n",
    "# Uncomment to test t5\n",
    "t5 = AutoModelForSeq2SeqLM.from_pretrained(t5_name).to(device)\n",
    "t5_tok = AutoTokenizer.from_pretrained(t5_name)\n",
    "\n",
    "print(f\"== strategy '{STRATEGY}' with T5 ==\")\n",
    "prompts, references = apply_mt_prompt_strategy(STRATEGY, dataset)\n",
    "predictions = seq2seq_inference(t5, t5_tok, prompts)\n",
    "\n",
    "for prompt, prediction, reference in zip(prompts, predictions, references):\n",
    "    print(f\"Prompt: '{prompt}'\")\n",
    "    print(f\"Prediction: '{prediction}'\")\n",
    "    print(f\"Reference: '{reference}'\",)\n",
    "\n",
    "scores = evaluate_bleu(predictions, references)\n",
    "print(f\"-> BLEU: {scores['score']}\", end='\\n\\n')\n",
    "\n",
    "\n",
    "# Uncomment to test GPT-2\n",
    "gpt2 = AutoModelForCausalLM.from_pretrained(gpt2_name).to(device)\n",
    "gpt2_tok = AutoTokenizer.from_pretrained(gpt2_name)\n",
    "\n",
    "print(f\"== strategy '{STRATEGY}' with GPT-2 ==\")\n",
    "prompts, references = apply_mt_prompt_strategy(STRATEGY, dataset)\n",
    "predictions = clm_inference(gpt2, gpt2_tok, prompts)\n",
    "\n",
    "for prompt, prediction, reference in zip(prompts, predictions, references):\n",
    "    print(f\"Prompt: '{prompt}'\")\n",
    "    print(f\"Prediction: '{prediction}'\")\n",
    "    print(f\"Reference: '{reference}'\")\n",
    "\n",
    "scores = evaluate_bleu(predictions, references)\n",
    "print(f\"-> BLEU: {scores['score']}\", end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d87e8a",
   "metadata": {},
   "source": [
    "Add your strategy, then run the cell below to evaluate all defined strategies on the validation set. Skim a few outputs to see what the model is doing (top cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5118d541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=   Evaluating T5   =\n",
      "== strategy 'minimal' ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:24<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 3.361462627466688, 'counts': [4560, 1127, 634, 366], 'totals': [34088, 32127, 30166, 28272], 'precisions': [13.377141516076039, 3.5079528122762786, 2.101703905058675, 1.2945670628183361], 'bp': 1.0, 'sys_len': 34088, 'ref_len': 31448}\n",
      "-> BLEU: 3.361462627466688\n",
      "\n",
      "== strategy 'minimal_instruction' ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:24<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 3.698354643371917, 'counts': [4781, 1136, 622, 351], 'totals': [29007, 27021, 25040, 23064], 'precisions': [16.482228427620917, 4.204137522667555, 2.484025559105431, 1.5218522372528616], 'bp': 0.9192914201170537, 'sys_len': 29007, 'ref_len': 31448}\n",
      "-> BLEU: 3.698354643371917\n",
      "\n",
      "== strategy 'instruction' ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:25<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 3.1754750932578806, 'counts': [3941, 1034, 581, 344], 'totals': [32436, 30791, 29151, 27512], 'precisions': [12.150080157849303, 3.35812412718002, 1.9930705636170285, 1.2503634777551613], 'bp': 1.0, 'sys_len': 32436, 'ref_len': 31448}\n",
      "-> BLEU: 3.1754750932578806\n",
      "\n",
      "\n",
      "=   Evaluating GPT-2   =\n",
      "== strategy 'minimal' ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:38<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> BLEU: 0.8773971640611861\n",
      "\n",
      "== strategy 'minimal_instruction' ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:38<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> BLEU: 0.5842604651120387\n",
      "\n",
      "== strategy 'instruction' ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:38<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> BLEU: 0.4003185845818317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = mt_validation\n",
    "\n",
    "print(\"=   Evaluating T5   =\")\n",
    "t5 = AutoModelForSeq2SeqLM.from_pretrained(t5_name).to(device)\n",
    "t5_tok = AutoTokenizer.from_pretrained(t5_name)\n",
    "for strategy_name in mt_prompt_strategies.keys():\n",
    "    print(f\"== strategy '{strategy_name}' ==\")\n",
    "    prompts, references = apply_mt_prompt_strategy(strategy_name, dataset)\n",
    "    predictions = seq2seq_inference(t5, t5_tok, prompts, batch_size=64)\n",
    "    scores = evaluate_bleu(predictions, references)\n",
    "    print(scores)\n",
    "    print(f\"-> BLEU: {scores['score']}\", end='\\n\\n')\n",
    "\n",
    "del t5\n",
    "clear_memory()\n",
    "\n",
    "print(\"\\n=   Evaluating GPT-2   =\")\n",
    "gpt2 = AutoModelForCausalLM.from_pretrained(gpt2_name).to(device)\n",
    "gpt2_tok = AutoTokenizer.from_pretrained(gpt2_name)\n",
    "for strategy_name in mt_prompt_strategies.keys():\n",
    "    print(f\"== strategy '{strategy_name}' ==\")\n",
    "    prompts, references = apply_mt_prompt_strategy(strategy_name, dataset)\n",
    "    predictions = clm_inference(gpt2, gpt2_tok, prompts, batch_size=64)\n",
    "    scores = evaluate_bleu(predictions, references)\n",
    "    print(f\"-> BLEU: {scores['score']}\", end='\\n\\n')\n",
    "\n",
    "del gpt2\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47336711",
   "metadata": {},
   "source": [
    "Before looking at scores alone, read a handful of translations. When outputs look off, is it the wrong language, a missing phrase, or a tense mismatch? A short qualitative pass often explains the numbers you see."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78ab6fe",
   "metadata": {},
   "source": [
    "**T5** seems to be the best, but both seem underperforming, right? **T5** was actually trained in translation too, so why is it that bad? Lets analyze its responses to see if the model is translating, and if so, to what language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7c128bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== T5 with strategy 'minimal_instruction' ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: 'Translate English to Spanish: If only we can get down to them.'\n",
      "reference: 'Si tan solo pudiéramos bajar.'\n",
      "prediction: 'Wenn wir nur auf sie zukommen.'\n",
      "expected: 'Spanish', got: 'German'\n",
      "\n",
      "prompt: 'Translate English to Spanish: Okay, that bitch is dead.'\n",
      "reference: 'Okay, esa perra esta muerta.'\n",
      "prediction: 'Okay, diese Hündin ist tot.'\n",
      "expected: 'Spanish', got: 'Afrikaans'\n",
      "\n",
      "prompt: 'Translate English to Spanish: This is some sort of joke, right?'\n",
      "reference: 'Esta es una especie de broma, ¿verdad?'\n",
      "prediction: 'Das ist eine Art Witz, oder?'\n",
      "expected: 'Spanish', got: 'German'\n",
      "\n",
      "prompt: 'Translate English to Spanish: Michaelson, can you hear me?'\n",
      "reference: 'Michaelson, puedes escucharme?'\n",
      "prediction: 'Michaelson, können Sie mich hören?'\n",
      "expected: 'Spanish', got: 'German'\n",
      "\n",
      "prompt: 'Translate English to Spanish: \"The ethical and moral responsibilities linked with scientific research can, then, be seen as an internal requirement of science inasmuch as it is a fully human activity, and not as a control or, worse still, an imposition that comes from outside.\"'\n",
      "reference: 'Más adelante, el Papa manifestó que \"las responsabilidades éticas y morales ligadas a la investigación científica deben ser tomadas como una exigencia interna a la ciencia en cuanto actividad plenamente humana, no como un control o una imposición que venga de fuera\".'\n",
      "prediction: '\"Die mit der wissenschaftlichen Forschung verbundenen ethischen und moralischen Verantwortlichkeiten können daher als interne Anforderung der Wissenschaft betrachtet werden, da sie eine voll menschliche Tätigkeit ist, und nicht als Kontrolle oder, schlimmer noch, als Auferlegung von außen.\"'\n",
      "expected: 'Spanish', got: 'German'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "from langdetect import detect, DetectorFactory\n",
    "from langcodes import Language\n",
    "DetectorFactory.seed = SEED\n",
    "\n",
    "STRATEGY = \"minimal_instruction\"\n",
    "\n",
    "t5 = AutoModelForSeq2SeqLM.from_pretrained(t5_name).to(device)\n",
    "print(f\"== T5 with strategy '{STRATEGY}' ==\")\n",
    "prompts, references = apply_mt_prompt_strategy(STRATEGY, dataset.select(range(5)))\n",
    "predictions = seq2seq_inference(t5, t5_tok, prompts, batch_size=32)\n",
    "\n",
    "for prompt, reference, prediction in zip(prompts, references, predictions):\n",
    "    print(f\"prompt: '{prompt}'\\nreference: '{reference}'\\nprediction: '{prediction}'\")\n",
    "    \n",
    "    try:\n",
    "        lang_ref = Language.make(detect(reference)).display_name()\n",
    "    except:\n",
    "        lang_ref = 'unk'\n",
    "    try:\n",
    "        lang_pred = Language.make(detect(prediction)).display_name()\n",
    "    except:\n",
    "        lang_pred = 'unk'\n",
    "\n",
    "    print(f\"expected: '{lang_ref}', got: '{lang_pred}'\\n\")\n",
    "    \n",
    "del t5\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca410e0",
   "metadata": {},
   "source": [
    "It seems that **T5** is translating. However instead of producing spanish it is producing German! This hints us to an important detail about the model pretraining. \n",
    "\n",
    "Actually, according to the model [documentation](https://huggingface.co/google-t5/t5-base) we see this:\n",
    "\n",
    "> Language(s) (NLP): English, French, Romanian, **German**\n",
    "\n",
    "So, troublesome as it is, Spanish is not a language this model has been trained on. Let us change that.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60ff785",
   "metadata": {},
   "source": [
    "### Fine‑tune `t5-base` for English→Spanish\n",
    "\n",
    "We’ll fine‑tune **T5** on our English→Spanish pairs. Each input is the prefixed English sentence; each target is the Spanish reference. A short run is often enough to make outputs more consistent and to reduce off‑target surprises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1aa61c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_ft = AutoModelForSeq2SeqLM.from_pretrained(t5_name)\n",
    "t5_tok = AutoTokenizer.from_pretrained(t5_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fd2787",
   "metadata": {},
   "source": [
    "For preprocessing, we will build our training prompts (as we want to teach the model to identify the task it ought to solve). We prefix inputs with `translate English to Spanish:` and preproces our dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9390f927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f2fa7468434ec6b16006bf14370326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/60000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "749553e2632746a7952c00b4fe159a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PREFIX = 'translate English to Spanish: '\n",
    "\n",
    "def preprocess_mt_t5(examples):\n",
    "    inputs  = [PREFIX + ex[\"en\"] for ex in examples[\"translation\"]]\n",
    "    targets = [ex[\"es\"] for ex in examples[\"translation\"]]\n",
    "    \n",
    "    # Simpler + recommended: one call with text_target\n",
    "    model_inputs = t5_tok(\n",
    "        inputs,\n",
    "        text_target=targets,\n",
    "        max_length=MAX_SOURCE_MT,\n",
    "        truncation=True\n",
    "    )\n",
    "    return model_inputs\n",
    "\n",
    "train_proc = mt_train.map(\n",
    "    preprocess_mt_t5, batched=True, remove_columns=mt_train.column_names\n",
    ")\n",
    "valid_proc = mt_validation.map(\n",
    "    preprocess_mt_t5, batched=True, remove_columns=mt_validation.column_names\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=t5_tok, model=t5_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cb7728",
   "metadata": {},
   "source": [
    "Notice we tokenize before training to keep batches consistent and the training loop simple. The key is that the loss only applies to real target tokens—not padding—so the model learns to write the translation, not special tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6eb407",
   "metadata": {},
   "source": [
    "Lastly, we can set our training parameters and execute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c58db64",
   "metadata": {},
   "source": [
    "We use standard seq2seq training arguments and enable `predict_with_generate=True` so validation scores reflect actual generations. Keep the run short; we’re looking for clear, explainable gains, not leaderboard numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c710b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2001' max='2814' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2001/2814 06:18 < 02:33, 5.28 it/s, Epoch 2.13/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.925400</td>\n",
       "      <td>1.579764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.654500</td>\n",
       "      <td>1.443117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.525900</td>\n",
       "      <td>1.371741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.458100</td>\n",
       "      <td>1.296776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.374600</td>\n",
       "      <td>1.266505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.264200</td>\n",
       "      <td>1.254626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.224400</td>\n",
       "      <td>1.227398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.199600</td>\n",
       "      <td>1.234246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.188400</td>\n",
       "      <td>1.195544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.131500</td>\n",
       "      <td>1.182381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:659] . unexpected pos 438121728 vs 438121620",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/torch/serialization.py:965\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[39m\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[32m--> \u001b[39m\u001b[32m965\u001b[39m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    972\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/torch/serialization.py:1266\u001b[39m, in \u001b[36m_save\u001b[39m\u001b[34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[39m\n\u001b[32m   1265\u001b[39m \u001b[38;5;66;03m# Now that it is on the CPU we can directly copy it into the zip file\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1266\u001b[39m \u001b[43mzip_file\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: [enforce fail at inline_container.cc:857] . PytorchStreamWriter failed writing file data/85: file write failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m      1\u001b[39m args = Seq2SeqTrainingArguments(\n\u001b[32m      2\u001b[39m     output_dir=\u001b[33m'\u001b[39m\u001b[33mt5_mt_en_es\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      3\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m     load_best_model_at_end=\u001b[38;5;28;01mTrue\u001b[39;00m,    \u001b[38;5;66;03m# after training, load the best checkpoint\u001b[39;00m\n\u001b[32m     33\u001b[39m )\n\u001b[32m     35\u001b[39m trainer = Seq2SeqTrainer(\n\u001b[32m     36\u001b[39m     model=t5_ft,\n\u001b[32m     37\u001b[39m     args=args,\n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m     data_collator=data_collator,\n\u001b[32m     42\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/transformers/trainer.py:2328\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2326\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2327\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2333\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/transformers/trainer.py:2754\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2752\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.epoch = epoch + (step + \u001b[32m1\u001b[39m + steps_skipped) / steps_in_epoch\n\u001b[32m   2753\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_step_end(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n\u001b[32m-> \u001b[39m\u001b[32m2754\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2755\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2756\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2757\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2758\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2759\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2760\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2761\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2762\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2763\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2764\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2765\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_substep_end(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/transformers/trainer.py:3234\u001b[39m, in \u001b[36mTrainer._maybe_log_save_evaluate\u001b[39m\u001b[34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[39m\n\u001b[32m   3231\u001b[39m         \u001b[38;5;28mself\u001b[39m.control.should_save = is_new_best_metric\n\u001b[32m   3233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.control.should_save:\n\u001b[32m-> \u001b[39m\u001b[32m3234\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3235\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_save(\u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/transformers/trainer.py:3342\u001b[39m, in \u001b[36mTrainer._save_checkpoint\u001b[39m\u001b[34m(self, model, trial)\u001b[39m\n\u001b[32m   3338\u001b[39m         \u001b[38;5;28mself\u001b[39m.state.best_model_checkpoint = best_checkpoint_dir\n\u001b[32m   3340\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.save_only_model:\n\u001b[32m   3341\u001b[39m     \u001b[38;5;66;03m# Save optimizer and scheduler\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3342\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_optimizer_and_scheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3343\u001b[39m     \u001b[38;5;28mself\u001b[39m._save_scaler(output_dir)\n\u001b[32m   3344\u001b[39m     \u001b[38;5;66;03m# Save RNG state\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/transformers/trainer.py:3469\u001b[39m, in \u001b[36mTrainer._save_optimizer_and_scheduler\u001b[39m\u001b[34m(self, output_dir)\u001b[39m\n\u001b[32m   3464\u001b[39m     save_fsdp_optimizer(\n\u001b[32m   3465\u001b[39m         \u001b[38;5;28mself\u001b[39m.accelerator.state.fsdp_plugin, \u001b[38;5;28mself\u001b[39m.accelerator, \u001b[38;5;28mself\u001b[39m.optimizer, \u001b[38;5;28mself\u001b[39m.model, output_dir\n\u001b[32m   3466\u001b[39m     )\n\u001b[32m   3467\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.should_save:\n\u001b[32m   3468\u001b[39m     \u001b[38;5;66;03m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3469\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOPTIMIZER_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3471\u001b[39m \u001b[38;5;66;03m# Save SCHEDULER & SCALER\u001b[39;00m\n\u001b[32m   3472\u001b[39m is_deepspeed_custom_scheduler = \u001b[38;5;28mself\u001b[39m.is_deepspeed_enabled \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m   3473\u001b[39m     \u001b[38;5;28mself\u001b[39m.lr_scheduler, DeepSpeedSchedulerWrapper\n\u001b[32m   3474\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/torch/serialization.py:964\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[39m\n\u001b[32m    961\u001b[39m     f = os.fspath(f)\n\u001b[32m    963\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[32m--> \u001b[39m\u001b[32m964\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[32m    965\u001b[39m         _save(\n\u001b[32m    966\u001b[39m             obj,\n\u001b[32m    967\u001b[39m             opened_zipfile,\n\u001b[32m   (...)\u001b[39m\u001b[32m    970\u001b[39m             _disable_byteorder_record,\n\u001b[32m    971\u001b[39m         )\n\u001b[32m    972\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/torch/serialization.py:798\u001b[39m, in \u001b[36m_open_zipfile_writer_file.__exit__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    797\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m798\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_end_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    799\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.file_stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    800\u001b[39m         \u001b[38;5;28mself\u001b[39m.file_stream.close()\n",
      "\u001b[31mRuntimeError\u001b[39m: [enforce fail at inline_container.cc:659] . unexpected pos 438121728 vs 438121620"
     ]
    }
   ],
   "source": [
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir='t5_mt_en_es',\n",
    "    \n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    learning_rate=4e-4,\n",
    "    max_grad_norm=1.0,\n",
    "\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=MAX_TARGET_MT,\n",
    "    seed=SEED,\n",
    "\n",
    "    # Efficiency\n",
    "    group_by_length=True,       # minimize padding in each batch\n",
    "\n",
    "    # Precision / memory\n",
    "    gradient_checkpointing=True,\n",
    "\n",
    "    # Logging & eval\n",
    "    report_to=[],\n",
    "    run_name=None,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=200,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    \n",
    "    save_strategy=\"no\",\n",
    "    #save_strategy=\"steps\",\n",
    "    #save_steps=400,\n",
    "    save_total_limit=1,             # keep only {best, most recent}\n",
    "    load_best_model_at_end=True,    # after training, load the best checkpoint\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=t5_ft,\n",
    "    args=args,\n",
    "    train_dataset=train_proc,\n",
    "    eval_dataset=valid_proc,\n",
    "    processing_class=t5_tok,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c33dee",
   "metadata": {},
   "source": [
    "Now lets see how our tuned model works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5034e3c8",
   "metadata": {},
   "source": [
    "Run the same evaluation as before on the test split. If BLEU improves, open a few before/after examples to see what changed. Are we staying in Spanish more reliably?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8a3fed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=   Evaluating fine-tuned T5 with strategy 'minimal_instruction' on Test! =\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:32<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> BLEU: 21.476097211416764\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"=   Evaluating fine-tuned T5 with strategy '{STRATEGY}' on Test! =\")\n",
    "t5 = trainer.model.eval()\n",
    "t5_tok = trainer.processing_class\n",
    "prompts, references = apply_mt_prompt_strategy(STRATEGY, dataset)\n",
    "predictions = seq2seq_inference(t5, t5_tok, prompts, batch_size=64)\n",
    "scores = evaluate_bleu(predictions, references)\n",
    "print(f\"-> BLEU: {scores['score']}\", end='\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82b80f4",
   "metadata": {},
   "source": [
    "The model improved from approx 3 to 22 in BLEU. A jump from a very low BLEU into the 20s is a healthy sign that fine‑tuning helped. It does not tell the whole though, as proper translation quality meassurement require more complex semantic and pragmatic approaches.\n",
    "\n",
    "However, we can use our judgement to see wether the translations improved by comparing a few example to the old ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "448776b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== T5 with strategy 'minimal_instruction' ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: 'Translate English to Spanish: If only we can get down to them.'\n",
      "reference: 'Si tan solo pudiéramos bajar.'\n",
      "prediction: 'Si sólo podemos irnos a ellos.'\n",
      "expected: 'Spanish', got: 'Spanish'\n",
      "\n",
      "prompt: 'Translate English to Spanish: Okay, that bitch is dead.'\n",
      "reference: 'Okay, esa perra esta muerta.'\n",
      "prediction: 'Bueno, esa horse está muerta.'\n",
      "expected: 'Spanish', got: 'Spanish'\n",
      "\n",
      "prompt: 'Translate English to Spanish: This is some sort of joke, right?'\n",
      "reference: 'Esta es una especie de broma, ¿verdad?'\n",
      "prediction: 'Esto es una gluma, verdad?'\n",
      "expected: 'Spanish', got: 'Spanish'\n",
      "\n",
      "prompt: 'Translate English to Spanish: Michaelson, can you hear me?'\n",
      "reference: 'Michaelson, puedes escucharme?'\n",
      "prediction: 'Michaelson, puedes escucharme?'\n",
      "expected: 'Spanish', got: 'Spanish'\n",
      "\n",
      "prompt: 'Translate English to Spanish: \"The ethical and moral responsibilities linked with scientific research can, then, be seen as an internal requirement of science inasmuch as it is a fully human activity, and not as a control or, worse still, an imposition that comes from outside.\"'\n",
      "reference: 'Más adelante, el Papa manifestó que \"las responsabilidades éticas y morales ligadas a la investigación científica deben ser tomadas como una exigencia interna a la ciencia en cuanto actividad plenamente humana, no como un control o una imposición que venga de fuera\".'\n",
      "prediction: '\"Las responsabilidades éticas y morales relacionadas con la investigación cientfica pueden ser vistas como una requisición interna de la cientfica en cuanto'\n",
      "expected: 'Spanish', got: 'Spanish'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "from langdetect import detect, DetectorFactory\n",
    "from langcodes import Language\n",
    "DetectorFactory.seed = SEED\n",
    "\n",
    "STRATEGY = \"minimal_instruction\"\n",
    "\n",
    "print(f\"== T5 with strategy '{STRATEGY}' ==\")\n",
    "prompts, references = apply_mt_prompt_strategy(STRATEGY, dataset.select(range(5)))\n",
    "predictions = seq2seq_inference(t5, t5_tok, prompts, batch_size=32)\n",
    "\n",
    "for prompt, reference, prediction in zip(prompts, references, predictions):\n",
    "    print(f\"prompt: '{prompt}'\\nreference: '{reference}'\\nprediction: '{prediction}'\")\n",
    "    \n",
    "    try:\n",
    "        lang_ref = Language.make(detect(reference)).display_name()\n",
    "    except:\n",
    "        lang_ref = 'unk'\n",
    "    try:\n",
    "        lang_pred = Language.make(detect(prediction)).display_name()\n",
    "    except:\n",
    "        lang_pred = 'unk'\n",
    "\n",
    "    print(f\"expected: '{lang_ref}', got: '{lang_pred}'\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72241a1",
   "metadata": {},
   "source": [
    "We did it! now **T5** knows how to translate somewhat to spanish! a totally new language it was not trained on originally!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "378963b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del t5_ft, t5, trainer\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6d4a1b",
   "metadata": {},
   "source": [
    "## Wrap‑up & what to try next\n",
    "\n",
    "You’ve now walked the full route twice: meet the data, write a clear prompt, choose sensible decoding, measure what you get, and fine‑tune to improve it. In QA, that meant short, precise answers; in translation, it meant staying in the right language and preserving meaning.\n",
    "\n",
    "If you want to keep exploring, change the prompt wording and decoding settings and see how tone and accuracy shift. Try a multilingual checkpoint and compare off‑target behavior. For translation, compute chrF alongside BLEU and decide which tells a better story for your sample. Keep a few before/after examples— they make improvements feel real.\n",
    "\n",
    "## References\n",
    "\n",
    "- **Stanford Question Answering Dataset (SQuAD)** – A reading‑comprehension dataset where crowdworkers ask questions about Wikipedia articles and answers are spans from the passages. SQuAD 2.0 also includes unanswerable questions.  The dataset is distributed under a CC BY‑SA 4.0 licence.\n",
    "\n",
    "- **OPUS‑100 multilingual corpus** – An English‑centric corpus covering 100 languages sampled from the OPUS collection.  The dataset is split into training, development and test sets; up to 1 million sentence pairs are sampled per language pair for training and up to 2 thousand pairs for development and test.\n",
    "\n",
    "- **T5‑Base model** – A 220‑million‑parameter Text‑to‑Text Transfer Transformer which reframes all NLP tasks into a unified text‑to‑text.  The base checkpoint supports English, French, Romanian and German and is released under the Apache 2.0 licence.\n",
    "\n",
    "- **GPT‑2 (small)** – A causal Transformer language model pretrained on a large corpus of English text to predict the next token.  The 124 M‑parameter version is suitable for downstream fine‑tuning and is distributed with an MIT licence.\n",
    "\n",
    "- **SacreBLEU** – An evaluation library for machine‑translation research that computes reproducible BLEU, chrF and TER scores. It wraps the WMT BLEU implementation and automatically downloads standard test sets.\n",
    "\n",
    "- **🤗 Evaluate** – A Hugging Face library providing a unified interface to dozens of evaluation metrics across NLP, computer vision and reinforcement learning tasks.\n",
    "\n",
    "- **TRL (Transformer Reinforcement Learning)** – A Hugging Face library offering tools for post‑training transformer models, including Supervised Fine‑Tuning (SFT) and reinforcement‑learning methods like GRPO and DPO. It integrates closely with the transformers library.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
