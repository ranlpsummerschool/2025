{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c668f70",
   "metadata": {},
   "source": [
    "# Practical Session: LLM Tools – Agentic Behaviour with LangGraph\n",
    "\n",
    "Welcome to this practical session at RANLP 2025. Over the next ninety minutes we will work together to build a small agentic system using **LangGraph**, a library that orchestrates long‑running workflows across language models and tools. To begin with we will see what a single model can do when asked to summarise a meeting transcript. Then we will gradually introduce structure: breaking the problem into multiple steps, adding loops and branching, and persisting state. LangGraph’s low‑level design makes it possible to checkpoint and resume long‑running agents and to weave in human feedback when needed. By the end of the session you will have a working prototype that reads a meeting transcript and produces a concise report with tasks and decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a07a231e-8092-45a0-92b6-fd29b44dccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip uninstall -q -y torch torchvision torchaudio transformers vllm datasets evaluate sacrebleu sentencepiece langgraph accelerate peft bitsandbytes pandas compressed-tensors spacy langcodes xgrammar vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b39e2a78-491f-4703-aa1b-b11f8ab618d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -q torch==2.7.1 torchaudio torchvision --index-url https://download.pytorch.org/whl/cu126\n",
    "#%pip install -q transformers datasets evaluate sacrebleu sentencepiece langgraph langchain langchain-community grandalf sentence-transformers langchain_huggingface langchain_openai accelerate>=0.21.0 peft bitsandbytes pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b02dd40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Environment setup\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Set a fixed seed for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Detect device\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device: {DEVICE}')\n",
    "\n",
    "# Create output directory\n",
    "OUT_DIR = './out'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b013cd",
   "metadata": {},
   "source": [
    "\n",
    "## Problem setting: meeting minutes\n",
    "\n",
    "Think back to your last research meeting or project stand‑up. Several people talk at once, ideas overlap and the conversation drifts before circling back. Important decisions and follow‑up tasks are easy to miss. In this practical we will design a helper that listens to these meetings and produces a clear summary and a list of tasks with assignees and deadlines. Given a raw transcript, our system will extract the salient points and update a shared task list so everyone knows what to do next.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31f9670",
   "metadata": {},
   "source": [
    "In the previous practical you saw that a strong foundation model can perform surprisingly well on a range of tasks without fine‑tuning. We'll start by using **Qwen2.5-14B-Instruct**, a 14‑billion‑parameter model that we will host locally, to see how far we can get with a simple prompt. We'll ask it to summarise a meeting transcript and extract action items. Examining the results will show us the strengths and weaknesses of a single LLM call and motivate a more structured approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa8ad50",
   "metadata": {},
   "source": [
    "### Experiment: direct prompting\n",
    "\n",
    "Take a look at the transcript provided in the next cell. It captures a short meeting among three colleagues and includes small talk, interruptions and overlapping topics to mimic the messy reality of meetings. We'll use this example to test our prompt and see how the base model handles summarisation and task extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "793b8bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = \"\"\"\n",
    "A: Good morning, everyone. Thanks for joining on short notice. I wanted us to sync about the product launch timeline because we`ve been getting questions from marketing.\n",
    "B: Morning! Yeah, I saw the emails yesterday. They`re pushing for a concrete date, but I don`t think engineering is fully comfortable committing yet.\n",
    "C: Exactly. We`re still ironing out some of the backend issues. The integration with the payment system isn`t as smooth as it should be, and if we push too quickly, we`ll have failures during checkout.\n",
    "A: Right, and we don`t want customers to be the ones finding those bugs. B, from your side, do you think another two weeks would make a difference?\n",
    "B: Two weeks sounds reasonable, but it depends on how quickly C`s team can finalize the fixes. If QA doesn`t get enough time, we`ll just be pushing the risk down the road.\n",
    "C: True, but we`ve made progress. Yesterday the team managed to cut down the error rate by almost 40%. If we keep that pace, by the end of next week we should be ready for a full round of regression tests.\n",
    "A: That`s encouraging. So maybe we can give marketing a tentative date, but with the condition that it`s dependent on QA sign-off.\n",
    "B: I think they`ll accept that as long as we word it clearly. They mainly need something to build their campaigns around.\n",
    "C: Should we aim for the 15th, then? That gives us a week to stabilize and a week for QA.\n",
    "A: Yes, let`s go with that. And if anything unexpected comes up, we`ll update. B, could you draft a short note to marketing after this call?\n",
    "B: Sure, I`ll take care of it. Do you want me to include the “tentative” language or phrase it as a “target date”?\n",
    "A: Better to say “target date,” but add that it`s subject to final QA approval. That way we`re transparent without sounding uncertain.\n",
    "C: Works for me. I`ll also send a daily progress update to both of you so we can react quickly if we see delays.\n",
    "B: Perfect. One last thing—A, are we still on for the client demo next Thursday?\n",
    "A: Yes, but let`s keep it internal features only. Nothing related to payments until we`re sure it`s solid.\n",
    "C: Good call. I`ll make sure the demo build is clean by Wednesday afternoon.\n",
    "A: Great. Thanks, both of you. I think we`ve got a clear plan now.\n",
    "B: Sounds good. Talk soon.\n",
    "C: Bye, everyone.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eef8fc",
   "metadata": {},
   "source": [
    "\n",
    "Let's run our baseline prompt on the short transcript and see what the model produces. Pay attention to whether the summary captures the key points and whether the extracted tasks have clear owners and deadlines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67713900",
   "metadata": {},
   "source": [
    "For these experiments we'll use the **LangChain** framework. **LangChain** provides a unified interface to different LLM providers, utilities for prompt templating and output parsing, and a simple way to chain components together. In the code you'll see we create a prompt template, call the Fireworks model and inspect the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64c9b2e",
   "metadata": {},
   "source": [
    "> A note on **LangChain**: **LangChain** gives us small building blocks—prompt templates, model wrappers, and a common “runnable” interface—so we can wire prompts to models without hard-coding strings or vendor-specific code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b132e986-05dc-4950-aae3-9410054f5bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c8a47e7110343a389e084ab8fc23010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd be happy to help summarize the transcript, but I need the content of the transcript first. Please provide the text you want summarized.\n",
      "cosine(similar tasks) ≈ 0.864\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
    "from langchain_huggingface import HuggingFacePipeline, ChatHuggingFace, HuggingFaceEmbeddings\n",
    "\n",
    "model_id = \"Qwen/Qwen2.5-14B-Instruct\"\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "bnb = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=\"bfloat16\")  # 4-bit\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb,\n",
    "    dtype=\"bfloat16\",\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map=\"auto\",\n",
    "    do_sample=False,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# IMPORTANT: set return_full_text=False so the prompt isn’t echoed back in the output\n",
    "gen = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tok,\n",
    "    max_new_tokens=8192,\n",
    "    do_sample=True,\n",
    "    pad_token_id=tok.eos_token_id,\n",
    "    return_full_text=False,  # without this, the full prompt is prepended\n",
    ")\n",
    "\n",
    "llm_raw = HuggingFacePipeline(pipeline=gen)\n",
    "llm = ChatHuggingFace(llm=llm_raw)\n",
    "\n",
    "# now invoke like a normal chat model\n",
    "resp = llm.invoke([\n",
    "    (\"system\", \"You are a helpful planning assistant.\"),\n",
    "    (\"human\", \"Summarise this transcript …\")\n",
    "])\n",
    "print(resp.content)\n",
    "\n",
    "\n",
    "embed_id = \"Qwen/Qwen3-Embedding-0.6B\"\n",
    "embed = HuggingFaceEmbeddings(\n",
    "    model_name=embed_id,\n",
    "    model_kwargs={\"device\": \"cuda\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    "    multi_process=False\n",
    ")\n",
    "\n",
    "\n",
    "a = embed.embed_query(\"get me icecream\")\n",
    "b = embed.embed_query(\"bring me vanilla icecream\")\n",
    "\n",
    "cos = sum(x*y for x,y in zip(a,b))\n",
    "print(\"cosine(similar tasks) ≈\", round(cos, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f413fd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a planning assistant in charge of analysing meeting transcripts to extract key information and tasks accurately.\"\n",
    "user_prompt = \"\"\"\n",
    "\n",
    "Analyze the meeting transcript:\n",
    "\n",
    "[Transcription]\n",
    "{transcript}\n",
    "[End Transcription]\n",
    "\n",
    "Extract key information and tasks. Your answer should be:\n",
    "\n",
    "1 - Meeting notes summary (a summary of work related content discussed in the meeting).\n",
    "2 - Tasks (specific tasks assigned to individuals or teams).\n",
    "3 - Decisions made (any important decisions or agreements reached during the meeting).\n",
    "4 - Updates on past tasks (status updates on previously assigned tasks).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e837dd97",
   "metadata": {},
   "source": [
    "`ChatPromptTemplate` lets us declare a sequence of chat messages—usually a `\"system\"` instruction plus a `\"human\"` message with placeholders like `{transcript}`—and render them into exactly what the model expects. It’s safer (no brittle string concatenation), easier to read, and it stays portable if we switch models later. You can think of it as a **form** where the transcript is the field we fill in; LangChain handles the formatting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8163b1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", user_prompt),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc26f097",
   "metadata": {},
   "source": [
    "LangChain introduces a concise syntax called the LangChain Expression Language (LCEL) that lets you compose *runnables* using a pipe operator (`|`). For example:\n",
    "\n",
    "```python\n",
    "(prompt | llm).invoke({\"transcript\": transcript_short})\n",
    "```\n",
    "\n",
    "first formats the input with the prompt and then passes the result to the model. This is analogous to Unix pipes: the output of one stage becomes the input to the next. Using `|` keeps our code clean and supports streaming and easy debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1666435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      " ### 1. Meeting Notes Summary\n",
      "The meeting focused on aligning the product launch timeline with marketing's requirements while ensuring technical readiness. Key points included:\n",
      "- Engineering is not fully prepared due to ongoing backend issues, particularly with the payment system integration.\n",
      "- There was a discussion on whether an additional two weeks would suffice for resolving these issues.\n",
      "- Significant progress has been made, reducing error rates by almost 40%.\n",
      "- A tentative launch date of the 15th was proposed, contingent upon successful QA sign-off.\n",
      "- The team agreed to maintain transparency while being realistic about timelines.\n",
      "- Preparations for a client demo were also discussed, limiting it to internal features until payment-related issues are resolved.\n",
      "\n",
      "### 2. Tasks\n",
      "- **B**: Draft a short note to marketing indicating the target launch date as the 15th, but subject to final QA approval.\n",
      "- **C**: Send daily progress updates to A and B regarding the backend fixes and any delays.\n",
      "- **C**: Ensure the demo build is free from payment-related features until further notice.\n",
      "- **All**: Monitor the situation closely and update stakeholders if there are any significant changes or delays.\n",
      "\n",
      "### 3. Decisions Made\n",
      "- Set the tentative target launch date for the product as the 15th, with the condition that it is subject to final QA approval.\n",
      "- Limit the client demo to internal features only, excluding payment functionalities until they are fully tested and stable.\n",
      "- Continue working towards stabilizing the backend and conducting thorough QA testing before proceeding with the launch.\n",
      "\n",
      "### 4. Updates on Past Tasks\n",
      "There were no explicit status updates provided for previously assigned tasks within the transcript. However, it was noted that the engineering team had made substantial progress, reducing the error rate by almost 40%, indicating active work on backend issues since the previous discussions.\n"
     ]
    }
   ],
   "source": [
    "response = (prompt | llm).invoke({\"transcript\": transcript})\n",
    "print(\"Response:\\n\", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc4f4f3",
   "metadata": {},
   "source": [
    "Take a moment to read the model's output. Does the summary reflect the main themes of the meeting? Are the tasks clearly identified with owners and due dates? Make note of any omissions or hallucinations—you'll use these observations to improve the pipeline in the next sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd25b1e",
   "metadata": {},
   "source": [
    "## Building a basic meeting‑minutes agent\n",
    "\n",
    "In the previous section you saw how a single prompt can summarise a meeting and extract tasks. However, relying on one prompt is brittle: important details are missed and tasks may be misassigned. In this stage we’ll construct a basic agent with LangGraph that decomposes the job into three nodes – one to summarise the transcript, one to extract tasks, and one to list explicit decisions. By structuring the workflow we’ll make each step simpler and easier to debug."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffee98fc",
   "metadata": {},
   "source": [
    "Before we can build our agent we need to define the state that flows through it. \n",
    "\n",
    "LangGraph uses *schemas* to describe the structure of the state. The main kinds of schemas you can provide to `StateGraph` are:\n",
    "\n",
    "- **state\\_schema** – describes the complete set of keys your graph may read or write. It can be a `TypedDict`, a `dataclass` or a Pydantic `BaseModel`.\n",
    "- **input\\_schema** – a subset of the state schema specifying which keys must be provided when you call `invoke`. When omitted, the state schema serves as the input schema.\n",
    "- **output\\_schema** – a subset of the state schema defining which keys are returned from the graph. Use this to hide internal channels or intermediate values.\n",
    "- **context\\_schema** – an optional read‑only structure passed to every node, used for immutable configuration or dependencies such as database connections.\n",
    "\n",
    "You can also define private state classes for channels that are only used for internal communication between nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0347b009",
   "metadata": {},
   "source": [
    "#### Step 1 - Summarisation Node\n",
    "\n",
    "For the first step the state only needs two fields: the original transcript and a summary that we’ll populate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cdc5bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal LangGraph imports\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# Our minimal state holds the meeting transcript and a summary.\n",
    "class OverallState(TypedDict):\n",
    "    transcript: str\n",
    "    summary: str\n",
    "\n",
    "# Define which keys are required as input when invoking the graph.\n",
    "class InputState(TypedDict):\n",
    "    transcript: str\n",
    "\n",
    "# Define which keys we want to expose at the end of the graph.\n",
    "class OutputState(TypedDict):\n",
    "    summary: str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ad31e4",
   "metadata": {},
   "source": [
    "We then write a summarize_node function that uses our chat model to produce a concise summary of the meeting. This node will read the transcript from the state and return a new dictionary with the summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a6907e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node: generate a concise summary of the meeting transcript using our LLM helper.\n",
    "def summarize_node(state: InputState) -> dict:\n",
    "    system_prompt = (\n",
    "        \"You are a planning assistant who writes very concise summaries of meetings. \"\n",
    "        \"Capture only the most important objectives and outcomes.\"\n",
    "    )\n",
    "    user_prompt = \"Summarize the following meeting transcript in a few sentences:{transcript}\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", user_prompt),\n",
    "    ])\n",
    "\n",
    "    response = (prompt | llm).invoke({\"transcript\": state[\"transcript\"]})\n",
    "    return {\"summary\": response.content}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8b6c38",
   "metadata": {},
   "source": [
    "Now, using LangGraph simple abstractions we define the different nodes and connect them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dc5bdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a minimal graph that just summarizes the transcript\n",
    "builder = StateGraph(OverallState, input_schema=InputState, output_schema=OutputState)\n",
    "builder.add_node('summarize', summarize_node)\n",
    "builder.set_entry_point('summarize')\n",
    "builder.add_edge('summarize', END)\n",
    "\n",
    "# Compile the graph\n",
    "summary_graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18e037b",
   "metadata": {},
   "source": [
    "Once the graph schema is completed, we compile it and invoke our agent passing the transcript in the **InputState**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c657aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: The meeting focused on aligning the product launch timeline due to marketing's requests for a specific date. Engineering highlighted unresolved backend issues, particularly with the payment system, necessitating more time for stabilization. After assessing recent improvements, a tentative launch target was set for the 15th of the month, subject to final QA approval. A will receive a detailed progress update daily. Additionally, the team agreed to proceed with an upcoming client demo focusing solely on internal features unrelated to payments until further validation is complete.\n"
     ]
    }
   ],
   "source": [
    "# Invoke the graph on our short transcript\n",
    "result = summary_graph.invoke({\"transcript\": transcript})\n",
    "print('Summary:', result['summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6173811e",
   "metadata": {},
   "source": [
    "#### Step 2 - Extracting Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d70670",
   "metadata": {},
   "source": [
    "A summary gives us the high‑level picture, but we also need to know what work needs to be done. We extend our state to include a `tasks` field and write a `tasks_node` function. This node asks the model to list each action item along with the person responsible and any deadlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2fc040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extended state with tasks\n",
    "class OverallState(TypedDict):\n",
    "    transcript: str\n",
    "    summary: str\n",
    "    tasks: str\n",
    "\n",
    "# Node: extract tasks\n",
    "def tasks_node(state: OverallState) -> dict:\n",
    "    system_prompt = (\n",
    "        \"You are a planning assistant who extracts tasks from meetings. \"\n",
    "        \"List each task with the responsible person and any deadlines. Use bullet points.\"\n",
    "    )\n",
    "    user_prompt = \"Extract the tasks from this meeting transcript:{transcript}\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", user_prompt),\n",
    "    ])\n",
    "\n",
    "    response = (prompt | llm).invoke({\"transcript\": state[\"transcript\"]})\n",
    "    return {\"tasks\": response.content}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09d488b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: The meeting focused on aligning the product launch timeline due to marketing's inquiries. Engineering highlighted unresolved backend issues, particularly with the payment system, suggesting a two-week delay for stability. The team agreed on aiming for a target launch date of the 15th, contingent upon final QA approval. Marketing will receive a formal notification shortly. Daily progress updates will be shared to address any unforeseen delays promptly. Additionally, the client demo will proceed with internal features only, excluding payment-related functionalities until further validation.\n",
      "Tasks: - **Draft a note to marketing regarding the product launch target date (by end of today)**  \n",
      "  Responsible: B\n",
      "\n",
      "- **Send daily progress updates on backend fixes**  \n",
      "  Responsible: C\n",
      "\n",
      "- **Prepare for the client demo (internal features only, no payments)**  \n",
      "  Responsible: C  \n",
      "  Deadline: Wednesday afternoon\n",
      "\n",
      "- **Ensure QA sign-off before finalizing the launch date**  \n",
      "  Responsible: C (implied, part of ongoing work)\n"
     ]
    }
   ],
   "source": [
    "# Build a graph with two sequential nodes: summarization followed by task extraction\n",
    "builder = StateGraph(OverallState)\n",
    "builder.add_node('summarize', summarize_node)\n",
    "builder.add_node('tasks', tasks_node)\n",
    "builder.set_entry_point('summarize')\n",
    "builder.add_edge('summarize', 'tasks')\n",
    "builder.add_edge('tasks', END)\n",
    "\n",
    "meeting_graph = builder.compile()\n",
    "\n",
    "result = meeting_graph.invoke({\"transcript\": transcript})\n",
    "print('Summary:', result['summary'])\n",
    "print('Tasks:', result['tasks'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec6c1c8",
   "metadata": {},
   "source": [
    "### Step 3: Capture Decisions\n",
    "\n",
    "Meetings often end with explicit decisions or agreements. To capture these, we add a `decisions` field to our state and write a `decisions_node`. This node lists the important decisions made during the meeting in bullet form. We then combine our three nodes into a single graph to produce a structured report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dca8361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend the state again to include decisions\n",
    "class OverallState(TypedDict):\n",
    "    transcript: str\n",
    "    summary: str\n",
    "    tasks: str\n",
    "    decisions: str\n",
    "\n",
    "def decisions_node(state: OverallState) -> dict:\n",
    "    system_prompt = (\n",
    "        \"You are a planning assistant who lists important decisions made during a meeting. \"\n",
    "        \"Return bullet points summarising each decision.\"\n",
    "    )\n",
    "    user_prompt = \"List any explicit decisions from this meeting transcript:{transcript}\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", user_prompt),\n",
    "    ])\n",
    "\n",
    "    response = (prompt | llm).invoke({\"transcript\": state[\"transcript\"]})\n",
    "    \n",
    "    return {\"decisions\": response.content}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbc5f2f7-b6a2-4443-9363-b7ca3ed810a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: The meeting focused on aligning the product launch timeline due to pressure from marketing for a concrete date. Engineering highlighted ongoing backend issues, particularly with payment system integration, suggesting another two weeks might be necessary before committing to a firm date. After discussing, they agreed on targeting the 15th for the launch, contingent upon final QA approval. Marketing will receive a note stating this as a \"target date\" with a clear mention of its dependency on QA sign-off. Additionally, daily progress updates will be shared to ensure quick responses to any potential delays. A reminder was set for an upcoming client demo, limiting it to internal features until payment-related issues are resolved.\n",
      "\n",
      "Tasks: - B to draft a short note to marketing stating the \"target date\" of the 15th, subject to final QA approval. Deadline: End of today.\n",
      "- C to send daily progress updates on backend fixes to A and B. Deadline: Daily until further notice.\n",
      "- C to ensure the demo build excludes payment-related features and is clean by Wednesday afternoon. Deadline: Wednesday afternoon.\n",
      "- A and B to prepare for the client demo focusing on internal features only, excluding payments. Deadline: Next Thursday.\n",
      "\n",
      "Decisions: - Set a target product launch date for the 15th of the current month.\n",
      "- Conditional upon final QA sign-off before proceeding with the launch.\n",
      "- Marketing will receive a note specifying the target date while noting its dependency on QA approval.\n",
      "- Conduct a daily progress update on backend issues to ensure timely communication.\n",
      "- Limit the upcoming client demo to internal features, excluding payment functionalities until further notice.\n"
     ]
    }
   ],
   "source": [
    "# Build a graph with three nodes: summarize -> tasks -> decisions\n",
    "builder = StateGraph(OverallState)\n",
    "builder.add_node('summarize', summarize_node)\n",
    "builder.add_node('tasks', tasks_node)\n",
    "builder.add_node('decisions', decisions_node)\n",
    "builder.set_entry_point('summarize')\n",
    "builder.add_edge('summarize', 'tasks')\n",
    "builder.add_edge('tasks', 'decisions')\n",
    "builder.add_edge('decisions', END)\n",
    "\n",
    "full_graph = builder.compile()\n",
    "\n",
    "result = full_graph.invoke({\"transcript\": transcript})\n",
    "print('Summary:', result['summary'], end='\\n\\n')\n",
    "print('Tasks:', result['tasks'], end='\\n\\n')\n",
    "print('Decisions:', result['decisions'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cf65fa",
   "metadata": {},
   "source": [
    "Our basic agent successfully decomposes the meeting summarisation problem into three steps: summarising the transcript, extracting tasks, and listing decisions. This simple graph demonstrates how LangGraph passes state between nodes and makes each step independent. However, the tasks are free‑form strings, meaning that some items might be missing, others could be ambiguous, and there is no way to validate them automatically. To build a more robust assistant we need to validate and refine the model’s outputs. In the next stage we will add a self‑reflection loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d12699",
   "metadata": {},
   "source": [
    "## 🧪 Exercise 1: Add a \"highlights\" node after the summary\n",
    "\n",
    "**What:** From the existing `summary` in state, create 2–3 concise bullet highlights.  \n",
    "**Why:** Practice adding a node that *derives* data from previous state, no LLM needed.\n",
    "\n",
    "**Rules:**\n",
    "- Use simple heuristics (split by sentences, pick the 2–3 most informative).\n",
    "- Return `{\"highlights\": List[str]}`.\n",
    "- Wire this node **after** `summary`.\n",
    "\n",
    "**Success check:** After running the graph, `state[\"highlights\"]` exists and is a short list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ea12442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for the graph here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543f711d",
   "metadata": {},
   "source": [
    "### Self‑reflection to improve task extraction\n",
    "\n",
    "In the basic agent we asked the model to list “tasks” and hoped for the best. Sometimes it works; other times it could miss items or invent details. We’re going to teach our agent to check its own work. The idea is simple: generate a first pass of tasks, run a small critic against a rubric (“don’t invent names or dates; keep titles concise; owners must appear in the transcript”), and if it fails, run a targeted repair pass before we accept the result. This follows the “reflection / Reflexion” pattern popular in agent design and is a natural fit for LangGraph because we can route on a condition and even loop a couple of times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0c3f8f",
   "metadata": {},
   "source": [
    "#### Step 1 - Standardise the task format\n",
    "\n",
    "We’ll switch from free-form task text to **typed objects**. That makes the critic’s job clear and the repair step easier to target. We use Pydantic models for `Task`, `TaskList`, and a tiny `Reflection` result. LangChain supports structured output via schema-aware prompts and parsers; we’ll use a Pydantic parser so this works with any chat model.\n",
    "\n",
    "We first define what a *Task* is. Binding this schema to the LLM makes the output predictable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182f2a07",
   "metadata": {},
   "source": [
    "Here we ask the model to return tasks as objects, then normalise and de-duplicate them with Pydantic v2. We accept natural phrasing for due_date (“next Friday”, “Q4”) and drop unknown fields so downstream code stays stable. The model may call fields by different names, so we use AliasChoices to map common variants (e.g., owner, assigned_to, who → assignee). Finally, a light model_validator filters obviously broken items and a pass of de-duplication removes near-duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "265a7857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List, Literal, Dict, Any\n",
    "from pydantic import BaseModel, Field, ConfigDict, field_validator, AliasChoices, model_validator\n",
    "import json\n",
    "\n",
    "Status = Literal[\"ToDo\", \"InProgress\", \"Done\", \"Closed\"]\n",
    "\n",
    "class Task(BaseModel):\n",
    "    model_config = ConfigDict(extra=\"ignore\")  # drop unexpected fields\n",
    "    title: str = Field(min_length=3, validation_alias=AliasChoices(\"title\", \"task\", \"name\"))\n",
    "    assignee: str = Field(min_length=1, validation_alias=AliasChoices(\"assignee\", \"person\", \"owner\", \"assigned_to\", \"who\"))\n",
    "    description: str = Field(min_length=1, validation_alias=AliasChoices(\"description\", \"details\", \"info\", \"notes\"))\n",
    "    # due_date intentionally free text; NO ISO enforcement (can be \"next week\", \"Q4\", etc.)\n",
    "    due_date: Optional[str] = Field(default=None, validation_alias=AliasChoices(\"due_date\", \"deadline\", \"when\", \"by\", \"due\"))\n",
    "    status: Status = \"ToDo\"\n",
    "\n",
    "    @field_validator(\"title\", \"assignee\", \"description\", \"due_date\", mode=\"before\")\n",
    "    @classmethod\n",
    "    def _strip(cls, v):\n",
    "        return v.strip() if isinstance(v, str) else v\n",
    "\n",
    "class TaskList(BaseModel):\n",
    "    tasks: List[Task]\n",
    "    \n",
    "    @model_validator(mode=\"before\")\n",
    "    @classmethod\n",
    "    def _normalize_and_filter(cls, v):\n",
    "        \"\"\"Accept various wrapper shapes and drop blatantly invalid task dicts early.\"\"\"\n",
    "        items = v if isinstance(v, list) else v.get(\"tasks\") if isinstance(v, dict) else None\n",
    "        if items is None and isinstance(v, dict) and isinstance(v.get(\"properties\"), dict):\n",
    "            maybe = v[\"properties\"].get(\"tasks\")\n",
    "            if isinstance(maybe, list):\n",
    "                items = maybe\n",
    "        if items is None:\n",
    "            return v  # let Pydantic raise later if shape invalid\n",
    "\n",
    "        filtered = []\n",
    "        for it in items:\n",
    "            if not isinstance(it, dict):\n",
    "                continue\n",
    "            title = (it.get(\"title\") or it.get(\"task\") or it.get(\"name\") or \"\").strip()\n",
    "            assignee = (it.get(\"assignee\") or it.get(\"person\") or it.get(\"owner\") or it.get(\"assigned_to\") or it.get(\"who\") or \"\").strip()\n",
    "            desc = (it.get(\"description\") or it.get(\"details\") or it.get(\"info\") or it.get(\"notes\") or \"\").strip()\n",
    "            if title and assignee and desc:\n",
    "                filtered.append(it)\n",
    "        return {\"tasks\": filtered}\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def _deduplicate(self):\n",
    "        \"\"\"Deduplicate tasks (case-insensitive on key fields) preserving first occurrence.\"\"\"\n",
    "        seen = set()\n",
    "        dedup = []\n",
    "        for t in self.tasks:\n",
    "            key = (\n",
    "                t.title.strip().lower(),\n",
    "                t.assignee.strip().lower(),\n",
    "                t.description.strip().lower(),\n",
    "                (t.due_date or \"\").strip().lower(),\n",
    "                t.status,\n",
    "            )\n",
    "            if key not in seen:\n",
    "                seen.add(key)\n",
    "                dedup.append(t)\n",
    "        self.tasks = dedup\n",
    "        return self\n",
    "\n",
    "def to_tasklist(x) -> TaskList:\n",
    "    if isinstance(x, TaskList):\n",
    "        return x\n",
    "    if isinstance(x, dict):\n",
    "        if \"tasks\" in x:                      # already TaskList-shaped\n",
    "            return TaskList.model_validate(x)\n",
    "        if x.get(\"parsed\") is not None:       # LCEL StructuredOutput shape\n",
    "            return TaskList.model_validate(x[\"parsed\"])\n",
    "        raw = x.get(\"raw\")\n",
    "        if raw is not None and hasattr(raw, \"content\"):  # fallback: parse LLM JSON text\n",
    "            data = json.loads(raw.content)\n",
    "            return TaskList.model_validate(data)\n",
    "    raise ValueError(f\"Unsupported tasks_struct shape: {type(x)}; keys={list(x.keys()) if isinstance(x, dict) else None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a1ec8d",
   "metadata": {},
   "source": [
    "Now, our new state should hold the `TaskList` the model is going to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1a44c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class OverallState(TypedDict):\n",
    "    transcript: str\n",
    "    summary: str\n",
    "    decisions: str\n",
    "    tasks_struct: TaskList  # validated list of Task dicts for downstream automation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cac1b09",
   "metadata": {},
   "source": [
    "LangChain’s `with_structured_output()` binds our Pydantic model to the chat model so the return value is already parsed and validated. We still give the model a short rubric to reduce guesswork. The prompt is assembled with ChatPromptTemplate, which keeps variables and messaging tidy.\n",
    "\n",
    "> Note: You must verify if your model allows this. This is a feature embedded into the LLM and allowed by the AI Provider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f07e061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasklist_llm = llm.with_structured_output(\n",
    "    TaskList,\n",
    "    method=\"json_schema\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af49cd6f",
   "metadata": {},
   "source": [
    "The `tasks_structured_node` node reads the meeting `transcript` and returns a validated `TaskList`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2c21c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA_CONSTRAINTS = \"\"\"\n",
    "    Schema & constraints:\n",
    "    - Only keys: title, description, assignee, due_date?, status.\n",
    "    - Title and Description are non-empty strings must be representative of the task at hand.\n",
    "    - Status ∈ [\"ToDo\", \"InProgress\", \"Done\", \"Closed\"] (exact casing).\n",
    "    - due_date is optional (null of free text); keep whatever natural phrasing appears (e.g. \"next Friday\", \"in two weeks\", \"Q4\"). Do NOT normalize to ISO.\n",
    "    - Assignee must be a non-empty string, is a speaker in the transcript.\n",
    "\"\"\"\n",
    "\n",
    "def tasks_structured_node(state: OverallState) -> Dict:\n",
    "    system_prompt = f\"\"\"\n",
    "        You are a planning assistant who extracts tasks from meeting transcripts.\n",
    "        Your goal is to identify and extract actionable tasks from a transcript.\n",
    "        Return ONLY a TaskList JSON *instance* (the data), not a JSON Schema.\n",
    "        The JSON must be valid and correct.\n",
    "\n",
    "        {SCHEMA_CONSTRAINTS}\n",
    "    \"\"\"\n",
    "    \n",
    "    user_prompt = \"Transcript:\\n{transcript}\\nYou must always return valid JSON object.\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", user_prompt),\n",
    "    ])\n",
    "    \n",
    "    tasklist = (prompt | tasklist_llm).invoke({\"transcript\": state[\"transcript\"]})\n",
    "    return {\"tasks_struct\": tasklist}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06029fa",
   "metadata": {},
   "source": [
    "We insert our new tasks_structured node between summarize and decisions. This keeps the flow readable and lets each node focus on one job. The code below reuses summarize_node and decisions_node from Stage 1; run those cells first if you skipped ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b61b218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "# Build a graph with three nodes: summarize -> tasks -> decisions\n",
    "builder = StateGraph(OverallState)\n",
    "builder.add_node('summarize', summarize_node)\n",
    "builder.add_node('tasks_structured', tasks_structured_node)\n",
    "builder.add_node('decisions', decisions_node)\n",
    "builder.set_entry_point('summarize')\n",
    "builder.add_edge('summarize', 'tasks_structured')\n",
    "builder.add_edge('tasks_structured', 'decisions')\n",
    "builder.add_edge('decisions', END)\n",
    "\n",
    "full_graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7911aa85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid json output: {\n",
      "  \"tasks\": [\n",
      "    {\n",
      "      \"title\": \"Draft note to marketing about the product launch target date\",\n",
      "      \"description\": \"B should draft a note mentioning the target launch date as the 15th, while clearly stating it's subject to final QA approval.\",\n",
      "      \"assignee\": \"B\",\n",
      "      \"due_date\": \"Today\",\n",
      "      \"status\": \"ToDo\"\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Send daily progress updates\",\n",
      "      \"description\": \"C should send daily updates on backend fixes to A and B.\",\n",
      "      \"assignee\": \"C\",\n",
      "      \"due_date\": \"Every day until the launch date\",\n",
      "      \"status\": \"ToDo\"\n",
      "    },\n",
      "    \"title\": \"Prepare client demo for next Thursday\",\n",
      "    \"description\": \"Ensure the demo build excludes payment features until QA is complete.\",\n",
      "    \"assignee\": \"C\",\n",
      "    \"due_date\": \"Wednesday afternoon\",\n",
      "    \"status\": \"ToDo\"\n",
      "  ]\n",
      "}\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    result = full_graph.invoke({\"transcript\": transcript})\n",
    "    print('Summary:', result['summary'], end='\\n\\n')\n",
    "    print('Tasks:')\n",
    "    \n",
    "    for t in to_tasklist(result['tasks_struct']).tasks:\n",
    "        pprint.pprint(t)\n",
    "        print()\n",
    "    print()\n",
    "    print('Decisions:', result['decisions'])\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8945bb5-9f25-452f-92b5-8a3155d66b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasklist_llm = llm.with_structured_output(\n",
    "    TaskList,\n",
    "    method=\"json_schema\", \n",
    "    include_raw=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9da939fd-262f-44e7-8204-e51d78b4c352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Fallback: try to auto-fix bad JSON then parse to TaskList\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain.output_parsers import PydanticOutputParser, OutputFixingParser, RetryOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d86ca1c-200f-46e1-81e2-2f206593f31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tasks_structured_node_reparse(state: OverallState) -> Dict:\n",
    "    system_prompt = f\"\"\"\n",
    "        You are a planning assistant who extracts tasks from meeting transcripts.\n",
    "        Your goal is to identify and extract actionable tasks from a transcript.\n",
    "        Return ONLY a TaskList JSON *instance* (the data), not a JSON Schema.\n",
    "        You must always return valid JSON object.\n",
    "\n",
    "        {SCHEMA_CONSTRAINTS}\n",
    "    \"\"\"\n",
    "    \n",
    "    user_prompt = \"Transcript:\\n{transcript}\\nYou must always return valid JSON object.\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", user_prompt),\n",
    "    ])\n",
    "\n",
    "    out = (prompt | tasklist_llm).invoke({\"transcript\": state[\"transcript\"]})\n",
    "    if out.get(\"parsed\") is not None:\n",
    "        tasklist = out[\"parsed\"]\n",
    "    else:\n",
    "        base = PydanticOutputParser(pydantic_object=TaskList)\n",
    "        fixing = OutputFixingParser.from_llm(parser=base, llm=llm, max_retries=5)\n",
    "        print(\"trying to parse:\", out[\"raw\"].content)\n",
    "        tasklist = fixing.parse(out[\"raw\"].content)  # <-- no prompt needed\n",
    "        print(tasklist)\n",
    "\n",
    "    return {\"tasks_struct\": to_tasklist(tasklist) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a47e4ae-66b5-458f-8a03-9b0c5dcc0528",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build a graph with three nodes: summarize -> tasks -> decisions\n",
    "builder = StateGraph(OverallState)\n",
    "builder.add_node('summarize', summarize_node)\n",
    "builder.add_node('tasks_structured', tasks_structured_node_reparse)\n",
    "builder.add_node('decisions', decisions_node)\n",
    "builder.set_entry_point('summarize')\n",
    "builder.add_edge('summarize', 'tasks_structured')\n",
    "builder.add_edge('tasks_structured', 'decisions')\n",
    "builder.add_edge('decisions', END)\n",
    "\n",
    "full_graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e8b4507-935e-44aa-a34a-8ea6450e2d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: The meeting focused on setting a product launch timeline, addressing concerns raised by marketing while ensuring engineering readiness. It was decided to set a target launch date of the 15th, contingent upon final QA approval. Engineering aims to resolve backend issues and complete regression testing by the end of next week. Marketing will receive a formal update post-meeting, and daily progress updates will be shared. Additionally, the team agreed to limit the upcoming client demo to internal features only, excluding payment-related functionalities until further validation.\n",
      "\n",
      "Tasks:\n",
      "Task(title='Draft a note to marketing regarding the product launch', assignee='B', description='Draft a note to marketing indicating the target date for the product launch is the 15th, but specify that this is subject to final QA approval.', due_date=None, status='ToDo')\n",
      "\n",
      "Task(title='Send daily progress updates', assignee='C', description='Send daily progress updates to A and B about the backend fixes and QA process.', due_date=None, status='ToDo')\n",
      "\n",
      "Task(title='Prepare a clean demo build', assignee='C', description='Ensure the demo build is clean by Wednesday afternoon, excluding payment-related features until QA is complete.', due_date='Wednesday afternoon', status='ToDo')\n",
      "\n",
      "\n",
      "Decisions: - Set the product launch target date for the 15th of the current month, subject to final QA approval.\n",
      "- Engineering will continue to work on backend issues and perform a full round of regression tests before the launch.\n",
      "- Marketing will receive a \"target date\" for the product launch, but with the understanding that it is conditional on QA sign-off.\n",
      "- Daily progress updates will be sent to all stakeholders involved in the product launch.\n",
      "- The upcoming client demo will focus on internal features only, excluding payment-related functionalities until further notice.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = full_graph.invoke({\"transcript\": transcript})\n",
    "print('Summary:', result['summary'], end='\\n\\n')\n",
    "print('Tasks:')\n",
    "\n",
    "for t in to_tasklist(result['tasks_struct']).tasks:\n",
    "    pprint.pprint(t)\n",
    "    print()\n",
    "print()\n",
    "print('Decisions:', result['decisions'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5118562",
   "metadata": {},
   "source": [
    "Great! now we have proper task extraction. Run the Cell above again a few times, you might see that once in a while, there are missalignments in the task detection. Sometimes it detects 3 tasks. Other times it detects 4, and so on.\n",
    "\n",
    "This is how our graph looks right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c1d89bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    +-----------+    \n",
      "    | __start__ |    \n",
      "    +-----------+    \n",
      "          *          \n",
      "          *          \n",
      "          *          \n",
      "    +-----------+    \n",
      "    | summarize |    \n",
      "    +-----------+    \n",
      "          *          \n",
      "          *          \n",
      "          *          \n",
      "+------------------+ \n",
      "| tasks_structured | \n",
      "+------------------+ \n",
      "          *          \n",
      "          *          \n",
      "          *          \n",
      "    +-----------+    \n",
      "    | decisions |    \n",
      "    +-----------+    \n",
      "          *          \n",
      "          *          \n",
      "          *          \n",
      "    +---------+      \n",
      "    | __end__ |      \n",
      "    +---------+      \n"
     ]
    }
   ],
   "source": [
    "# from IPython.display import Image, display\n",
    "# display(Image(full_graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "print(full_graph.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94df079f",
   "metadata": {},
   "source": [
    "#### Step 2 - Critique and repair the task list\n",
    "\n",
    "Even with a schema, the model sometimes omits tasks or includes spurious ones. We can improve reliability by adding a critic. We define a `Reflection` Pydantic model with three fields: `approve` (a boolean indicating whether the current task list meets our rubric), `issues` (a list of short descriptions of problems) and `instructions` (concise guidance on how to fix those problems). A critic node uses this model to decide whether the candidate task list is acceptable. If it isn’t, a repair node generates a revised list following the critic’s instructions. We loop between critic and repair until the tasks are approved or a maximum number of iterations is reached. LangGraph’s conditional edges and immutable state make it easy to express this loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b537c3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_REFLECTION_LOOPS = 3 # keep tiny for speed & determinism\n",
    "\n",
    "class Reflection(BaseModel):\n",
    "    approve: bool = Field(..., description=\"True if the candidate TaskList passes the rubric.\")\n",
    "    issues: List[str] = Field(default_factory=list, description=\"Concise bullet points of problems found.\")\n",
    "    instructions: str = Field(..., description=\"Short, actionable instructions to revise the TaskList.\")\n",
    "\n",
    "    @field_validator(\"instructions\", mode=\"before\")\n",
    "    @classmethod\n",
    "    def _norm_instructions(cls, v):\n",
    "        # Accept list[str] or str; normalize to a single newline-separated string\n",
    "        if isinstance(v, list):\n",
    "            return \"\\n\".join(s.strip() for s in v if str(s).strip())\n",
    "        return str(v).strip()\n",
    "\n",
    "    \n",
    "def to_reflection(x) -> Reflection:\n",
    "    if isinstance(x, Reflection):\n",
    "        return x\n",
    "    if hasattr(Reflection, \"model_validate\"):\n",
    "        return Reflection.model_validate(x)\n",
    "    return Reflection.parse_obj(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf22b7f",
   "metadata": {},
   "source": [
    "Our `OverallState` now has to support storing critics and attempt counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a2bf56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OverallState(TypedDict):\n",
    "    transcript: str\n",
    "    summary: str\n",
    "    decisions: str\n",
    "    tasks_struct: TaskList\n",
    "    approved: bool\n",
    "    attempts: int\n",
    "    issues: List[str]\n",
    "    instructions: str\n",
    "    history: List[Dict[str, Any]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4efc55",
   "metadata": {},
   "source": [
    "We encode the acceptance rubric in the critic’s system prompt, and bind both critic and repair to structured outputs so they return `Reflection` and `TaskList` objects directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1d93369",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTIONS_STYLE = \"\"\"\n",
    "    - '+ title=... assignee=...': add a grounded task; ensure fields are supported by cited lines.\n",
    "    - '- title=... assignee=...': remove EXACT matching task if present.\n",
    "    - '~ title=... assignee=... field=... -> ...': modify the specified field value only.\n",
    "\"\"\"\n",
    "\n",
    "REFLECTION_SYSTEM = f\"\"\"\n",
    "    You are a TASK QUALITY AUDITOR. Review a candidate TaskList against this rubric:\n",
    "\n",
    "    {SCHEMA_CONSTRAINTS}\n",
    "\n",
    "    GROUNDING REQUIREMENT:\n",
    "    For every issue you raise, cite supporting transcript line numbers like L12 or ranges L34-L37. You will receive the transcript as a single block; treat each newline-delimited utterance as one line (first line = L1). If evidence spans non-contiguous lines, list them comma-separated.\n",
    "\n",
    "    Return a Reflection JSON: approve (bool), issues (list of strings), instructions (string).\n",
    "\n",
    "    All Instructions MUST be a plan consisting of one directive per line. For example:\n",
    "\n",
    "    {INSTRUCTIONS_STYLE}\n",
    "\n",
    "    Reject on any violation but accept clear interpretations that might not be explicit.\n",
    "    You must always return valid JSON object.\n",
    "\"\"\"\n",
    "\n",
    "REPAIR_SYSTEM = f\"\"\"\n",
    "    You are a TASK REPAIR EXPERT. You will receive a transcript, a candidate list of TASKS and some Instructions to fix the TASKS.\n",
    "\n",
    "    You must follow ONLY the Instructions and FIX the TASKS accordingly. Treat them atomically:\n",
    "    {INSTRUCTIONS_STYLE}\n",
    "\n",
    "    Preserve unchanged tasks.\n",
    "    If a directive cannot be executed due to missing grounding, SKIP it (do not guess).\n",
    "    You must always return valid JSON object..\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0aac67f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", REFLECTION_SYSTEM),\n",
    "        (\"human\", \n",
    "            (\n",
    "                \"Transcript (for grounding; each line is numbered implicitly by order):\\n{transcript}\\n\\n\"\\\n",
    "                \"Candidate TaskList JSON:\\n{candidate_json}\\n\\n\"\\\n",
    "                \"You must always return valid JSON object.\"\n",
    "            ),\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "repair_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "    (\"system\", REPAIR_SYSTEM),\n",
    "    (\"human\", \n",
    "        (\n",
    "            \"Transcript:\\n{transcript}\\n\\n\"\\\n",
    "            \"Candidate TaskList JSON (to revise):\\n{candidate_json}\\n\\n\"\\\n",
    "            \"Diff-style critic instructions:\\n{instructions}\\n\\n\"\\\n",
    "            \"FOLLOW THE INSTRUCTIONS and Fix the TaskList. You must always return valid JSON object.\"\n",
    "        ),\n",
    "    )\n",
    "    ]\n",
    ")\n",
    "\n",
    "reflection_llm = llm.with_structured_output(\n",
    "    Reflection, \n",
    "    method=\"json_schema\",\n",
    "    include_raw=True\n",
    ")\n",
    "\n",
    "critic_chain = critic_prompt | reflection_llm\n",
    "repair_chain = repair_prompt | tasklist_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5b2623",
   "metadata": {},
   "source": [
    "Now, our `reflect_node` runs the critic. If the critic approves or we hit the loop cap, we stop; otherwise we store instructions for the repair step.\n",
    "`repair_node` regenerates a corrected `TaskList` using the critic’s instructions. We also append a small history trail for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f298fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflect_node(state: OverallState) -> Dict[str, Any]:\n",
    "    candidate_json = to_tasklist(state[\"tasks_struct\"]).model_dump_json()\n",
    "    attempts = state.get(\"attempts\", 0)\n",
    "    history = state.get(\"history\", [])\n",
    "\n",
    "    # Pass raw transcript; critic infers line numbers by order.\n",
    "    response = critic_chain.invoke( {\n",
    "            \"transcript\": state[\"transcript\"],\n",
    "            \"candidate_json\": candidate_json\n",
    "    })\n",
    "    \n",
    "    if response.get(\"parsed\") is not None:\n",
    "        reflection = response[\"parsed\"]\n",
    "    else:\n",
    "        base = PydanticOutputParser(pydantic_object=Reflection)\n",
    "        fixing = OutputFixingParser.from_llm(parser=base, llm=llm, max_retries=5)\n",
    "        print(\"trying to parse (reflection):\", response[\"raw\"].content)\n",
    "        reflection = fixing.parse(response[\"raw\"].content)  # <-- no prompt needed\n",
    "        \n",
    "    reflection = to_reflection(reflection)\n",
    "    reflection_approved = reflection.approve and not reflection.issues\n",
    "    \n",
    "    out = {\n",
    "        \"approved\": reflection_approved,\n",
    "        \"issues\": reflection.issues,\n",
    "        \"history\": history + [{\"stage\": \"reflect\", **reflection.model_dump()}],\n",
    "        \"attempts\": attempts,  # increment on repair\n",
    "    }\n",
    "\n",
    "    if reflection_approved or attempts >= MAX_REFLECTION_LOOPS:\n",
    "        return out\n",
    "    \n",
    "    print(f\"Reflection found issues (attempt {attempts + 1}):\")\n",
    "    for issue in reflection.issues:\n",
    "        print(f\" - {issue}\")\n",
    "    print()\n",
    "\n",
    "    out[\"instructions\"] = reflection.instructions\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1289745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair_node(state: OverallState) -> Dict[str, Any]:    \n",
    "    candidate_json = to_tasklist(state[\"tasks_struct\"]).model_dump_json()\n",
    "    attempts = state.get(\"attempts\", 0)\n",
    "    history = state.get(\"history\", [])\n",
    "\n",
    "    response = repair_chain.invoke(\n",
    "        {\n",
    "            \"transcript\": state[\"transcript\"],\n",
    "            \"candidate_json\": candidate_json,\n",
    "            \"instructions\": state.get(\"instructions\", \"\"),\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    if response.get(\"parsed\") is not None:\n",
    "        fixed = response[\"parsed\"]\n",
    "    else:\n",
    "        base = PydanticOutputParser(pydantic_object=Reflection)\n",
    "        fixing = OutputFixingParser.from_llm(parser=base, llm=llm, max_retries=5)\n",
    "        print(\"trying to parse (repair):\", response[\"raw\"].content)\n",
    "        fixed = fixing.parse(response[\"raw\"].content)  # <-- no prompt needed\n",
    "\n",
    "    fixed_tl = to_tasklist(fixed)\n",
    "    print(f\"Repair attempt {attempts + 1} completed. New Tasks (n={len(fixed_tl.tasks)}):\")\n",
    "    for t in fixed_tl.tasks:\n",
    "        print(f\"  - {t.title} [{t.assignee}]  due={t.due_date}  status={t.status}\")\n",
    "\n",
    "    return {\n",
    "        \"tasks_struct\": fixed_tl,\n",
    "        \"attempts\": attempts + 1,\n",
    "        \"history\": history + [{\"stage\": \"repair\", \"tasks\": fixed_tl.model_dump()}],\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"tasks_struct\": fixed_tl,\n",
    "        \"attempts\": attempts + 1,\n",
    "        \"history\": history + [{\"stage\": \"repair\", \"tasks\": fixed_tl}],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd74de6",
   "metadata": {},
   "source": [
    "Now, we should wire the loop with a gate\n",
    "\n",
    "We send control `tasks_structured → reflect → (approved? decisions : repair → reflect …)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24e2c1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "builder = StateGraph(OverallState)\n",
    "builder.add_node(\"summarize\", summarize_node) # existing\n",
    "builder.add_node(\"tasks_structured\", tasks_structured_node_reparse) # existing\n",
    "builder.add_node(\"reflect\", reflect_node) # new\n",
    "builder.add_node(\"repair\", repair_node) # new\n",
    "builder.add_node(\"decisions\", decisions_node) # existing\n",
    "\n",
    "builder.set_entry_point(\"summarize\")\n",
    "builder.add_edge(\"summarize\", \"tasks_structured\")\n",
    "builder.add_edge(\"tasks_structured\", \"reflect\")\n",
    "\n",
    "def _gate(state: OverallState) -> str:\n",
    "    # stop if approved or we've reached the small retry cap\n",
    "    if state.get(\"approved\") or state.get(\"attempts\", 0) >= MAX_REFLECTION_LOOPS:\n",
    "        return \"decisions\"\n",
    "    return \"repair\"\n",
    "\n",
    "builder.add_conditional_edges(\"reflect\", _gate, {\"repair\": \"repair\", \"decisions\": \"decisions\"})\n",
    "builder.add_edge(\"repair\", \"reflect\")\n",
    "builder.add_edge(\"decisions\", END)\n",
    "\n",
    "full_graph_reflect_2 = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b8e7cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying to parse: {\n",
      "    \"tasks\": [\n",
      "        {\n",
      "            \"title\": \"Draft note to marketing about product launch target date\",\n",
      "            \"description\": \"Write a note mentioning the tentative launch date of 15th, but explicitly state that it's subject to final QA approval.\",\n",
      "            \"assignee\": \"B\",\n",
      "            \"due_date\": \"before the end of this week\",\n",
      "            \"status\": \"ToDo\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"Send daily progress updates\",\n",
      "            \"description\": \"Provide regular updates on the backend work to A and B.\",\n",
      "            \"assignee\": \"C\",\n",
      "            \"due_date\": \"daily until further notice\",\n",
      "            \"status\": \"ToDo\"\n",
      "        },\n",
      "        \"title\": \"Prepare clean demo build\",\n",
      "        \"description\": \"Ensure the demo build does not include any unstable payment features and is ready by Wednesday afternoon.\",\n",
      "            \"assignee\": \"C\",\n",
      "            \"due_date\": \"Wednesday afternoon\",\n",
      "            \"status\": \"ToDo\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "tasks=[Task(title='Draft note to marketing about product launch target date', assignee='B', description=\"Write a note mentioning the tentative launch date of 15th, but explicitly state that it's subject to final QA approval.\", due_date='before the end of this week', status='ToDo'), Task(title='Send daily progress updates', assignee='C', description='Provide regular updates on the backend work to A and B.', due_date='daily until further notice', status='ToDo'), Task(title='Prepare clean demo build', assignee='C', description='Ensure the demo build does not include any unstable payment features and is ready by Wednesday afternoon.', due_date='Wednesday afternoon', status='ToDo')]\n",
      "Reflection found issues (attempt 1):\n",
      " - The first task description mentions 'tentative launch date' which contradicts the agreed upon 'target date' with a specific qualifier.\n",
      " - Second task has an ambiguous 'daily until further notice' due_date, it should specify an end date or criteria to stop sending updates.\n",
      " - Third task description is accurate but lacks context on what 'unstable payment features' means, which may cause confusion.\n",
      "\n",
      "Repair attempt 1 completed. New Tasks (n=3):\n",
      "  - Draft note to marketing about product launch target date [B]  due=before the end of this week  status=ToDo\n",
      "  - Send daily progress updates [C]  due=Until the product launch  status=ToDo\n",
      "  - Confirm no unstable payment features in demo build [C]  due=Wednesday afternoon  status=ToDo\n",
      "Reflection found issues (attempt 2):\n",
      " - Task 'Draft note to marketing about product launch target date' has incorrect due_date; should be 'before the end of this week' based on L39.\n",
      "\n",
      "Repair attempt 2 completed. New Tasks (n=2):\n",
      "  - Send daily progress updates [C]  due=Until the product launch  status=ToDo\n",
      "  - Confirm no unstable payment features in demo build [C]  due=Wednesday afternoon  status=ToDo\n",
      "Reflection found issues (attempt 3):\n",
      " - Task 'Send daily progress updates' lacks a specific end date. While the transcript suggests ongoing communication, the rubric requires tasks to either have a due_date or indicate an open-ended timeframe.\n",
      " - Task 'Confirm no unstable payment features in demo build' is accurate but missing the exact due date of 'next Thursday'. According to the transcript, the demo should happen next Thursday and the build needs to be prepared by Wednesday afternoon.\n",
      "\n",
      "Repair attempt 3 completed. New Tasks (n=3):\n",
      "  - Send daily progress updates [C]  due=Until the product launch  status=ToDo\n",
      "  - Client demo preparation [C]  due=Wednesday afternoon  status=ToDo\n",
      "  - Draft note to marketing about tentative launch date [B]  due=After this call  status=ToDo\n",
      "\n",
      "Refined tasks after reflection:\n",
      "[Task(title='Send daily progress updates', assignee='C', description='Provide regular updates on the backend work to A and B.', due_date='Until the product launch', status='ToDo'),\n",
      " Task(title='Client demo preparation', assignee='C', description='Prepare the demo build by Wednesday afternoon to exclude any unstable payment features and focus on internal features only.', due_date='Wednesday afternoon', status='ToDo'),\n",
      " Task(title='Draft note to marketing about tentative launch date', assignee='B', description='Write a brief message to marketing indicating the 15th as the target launch date, subject to final QA approval.', due_date='After this call', status='ToDo')]\n",
      "\n",
      "Approved? False  | Attempts: 3\n",
      "Critic issues:\n",
      " - The first task's description should specify 'until the product launch' as its due date, not 'Until the product launch'.\n",
      " - The second task's title should be 'Prepare demo build excluding payment features', since it focuses on preparing an internal feature demo.\n",
      " - The third task's due date should be more specific, such as 'by end of today', given the context of drafting a note immediately after the call.\n"
     ]
    }
   ],
   "source": [
    "refl_state_2 = full_graph_reflect_2.invoke({\"transcript\": transcript})\n",
    "\n",
    "print(\"\\nRefined tasks after reflection:\")\n",
    "pprint.pprint(to_tasklist(refl_state_2[\"tasks_struct\"]).tasks)\n",
    "\n",
    "print(\"\\nApproved?\", refl_state_2.get(\"approved\"), \" | Attempts:\", refl_state_2.get(\"attempts\", 0))\n",
    "if refl_state_2.get(\"issues\"):\n",
    "    print(\"Critic issues:\", *refl_state_2[\"issues\"], sep=\"\\n - \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919f44da",
   "metadata": {},
   "source": [
    "This is how our new graph looks like. You can see we have a small cycle following the Reflexion pattern, in which externally from the actual generation, we get an evaluation and instructions to fix/improve the generated tasks. Then, the repair node take those instructions and try to fix the candidate response previously shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f56f785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         +-----------+             \n",
      "         | __start__ |             \n",
      "         +-----------+             \n",
      "                *                  \n",
      "                *                  \n",
      "                *                  \n",
      "         +-----------+             \n",
      "         | summarize |             \n",
      "         +-----------+             \n",
      "                *                  \n",
      "                *                  \n",
      "                *                  \n",
      "      +------------------+         \n",
      "      | tasks_structured |         \n",
      "      +------------------+         \n",
      "                *                  \n",
      "                *                  \n",
      "                *                  \n",
      "          +---------+              \n",
      "          | reflect |              \n",
      "          +---------+              \n",
      "          **         ..            \n",
      "        **             ..          \n",
      "       *                 .         \n",
      "+--------+          +-----------+  \n",
      "| repair |          | decisions |  \n",
      "+--------+          +-----------+  \n",
      "                          *        \n",
      "                          *        \n",
      "                          *        \n",
      "                     +---------+   \n",
      "                     | __end__ |   \n",
      "                     +---------+   \n"
     ]
    }
   ],
   "source": [
    "# display(Image(full_graph_reflect.get_graph().draw_mermaid_png()))\n",
    "print(full_graph_reflect_2.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f1e2f8",
   "metadata": {},
   "source": [
    "Lets take a peek at the history. Lets see why the gate decided to stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4688618d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transcript': '\\nA: Good morning, everyone. Thanks for joining on short notice. I wanted us to sync about the product launch timeline because we`ve been getting questions from marketing.\\nB: Morning! Yeah, I saw the emails yesterday. They`re pushing for a concrete date, but I don`t think engineering is fully comfortable committing yet.\\nC: Exactly. We`re still ironing out some of the backend issues. The integration with the payment system isn`t as smooth as it should be, and if we push too quickly, we`ll have failures during checkout.\\nA: Right, and we don`t want customers to be the ones finding those bugs. B, from your side, do you think another two weeks would make a difference?\\nB: Two weeks sounds reasonable, but it depends on how quickly C`s team can finalize the fixes. If QA doesn`t get enough time, we`ll just be pushing the risk down the road.\\nC: True, but we`ve made progress. Yesterday the team managed to cut down the error rate by almost 40%. If we keep that pace, by the end of next week we should be ready for a full round of regression tests.\\nA: That`s encouraging. So maybe we can give marketing a tentative date, but with the condition that it`s dependent on QA sign-off.\\nB: I think they`ll accept that as long as we word it clearly. They mainly need something to build their campaigns around.\\nC: Should we aim for the 15th, then? That gives us a week to stabilize and a week for QA.\\nA: Yes, let`s go with that. And if anything unexpected comes up, we`ll update. B, could you draft a short note to marketing after this call?\\nB: Sure, I`ll take care of it. Do you want me to include the “tentative” language or phrase it as a “target date”?\\nA: Better to say “target date,” but add that it`s subject to final QA approval. That way we`re transparent without sounding uncertain.\\nC: Works for me. I`ll also send a daily progress update to both of you so we can react quickly if we see delays.\\nB: Perfect. One last thing—A, are we still on for the client demo next Thursday?\\nA: Yes, but let`s keep it internal features only. Nothing related to payments until we`re sure it`s solid.\\nC: Good call. I`ll make sure the demo build is clean by Wednesday afternoon.\\nA: Great. Thanks, both of you. I think we`ve got a clear plan now.\\nB: Sounds good. Talk soon.\\nC: Bye, everyone.\\n',\n",
       " 'summary': 'The meeting focused on aligning the product launch timeline, addressing concerns from marketing regarding a concrete launch date. Engineering highlighted ongoing backend integration issues, particularly with the payment system, suggesting a tentative launch date of the 15th, contingent upon successful QA testing. Marketing will be informed of this \"target date\" while noting its dependency on final QA approval. Daily updates will be provided to monitor progress, and preparations for an upcoming client demo were also discussed, limiting it to internal features excluding payments until further validation.',\n",
       " 'decisions': '- Set the product launch target date for the 15th of the current month.\\n- Condition the launch date on final QA sign-off.\\n- A will draft a short note to marketing confirming the \"target date\" while emphasizing its dependency on QA approval.\\n- Schedule an internal-only client demo focusing on non-payment features for next Thursday.\\n- C will provide daily progress updates to ensure quick response to any potential delays.',\n",
       " 'tasks_struct': TaskList(tasks=[Task(title='Send daily progress updates', assignee='C', description='Provide regular updates on the backend work to A and B.', due_date='Until the product launch', status='ToDo'), Task(title='Client demo preparation', assignee='C', description='Prepare the demo build by Wednesday afternoon to exclude any unstable payment features and focus on internal features only.', due_date='Wednesday afternoon', status='ToDo'), Task(title='Draft note to marketing about tentative launch date', assignee='B', description='Write a brief message to marketing indicating the 15th as the target launch date, subject to final QA approval.', due_date='After this call', status='ToDo')]),\n",
       " 'approved': False,\n",
       " 'attempts': 3,\n",
       " 'issues': [\"The first task's description should specify 'until the product launch' as its due date, not 'Until the product launch'.\",\n",
       "  \"The second task's title should be 'Prepare demo build excluding payment features', since it focuses on preparing an internal feature demo.\",\n",
       "  \"The third task's due date should be more specific, such as 'by end of today', given the context of drafting a note immediately after the call.\"],\n",
       " 'instructions': '- title=\"Send daily progress updates\" assignee=\"C\"\\n~ title=\"Confirm no unstable payment features in demo build\" assignee=\"C\" field=\"due_date\" -> \"Wednesday afternoon\"\\n+ title=\"Draft note to marketing about tentative launch date\" assignee=\"B\" description=\"Write a brief message to marketing indicating the 15th as the target launch date, subject to final QA approval.\" due_date=\"After this call\" status=\"ToDo\"\\n+ title=\"Client demo preparation\" assignee=\"C\" description=\"Prepare the demo build by Wednesday afternoon to exclude any unstable payment features and focus on internal features only.\" due_date=\"Wednesday afternoon\" status=\"ToDo\"',\n",
       " 'history': [{'stage': 'reflect',\n",
       "   'approve': False,\n",
       "   'issues': [\"The first task description mentions 'tentative launch date' which contradicts the agreed upon 'target date' with a specific qualifier.\",\n",
       "    \"Second task has an ambiguous 'daily until further notice' due_date, it should specify an end date or criteria to stop sending updates.\",\n",
       "    \"Third task description is accurate but lacks context on what 'unstable payment features' means, which may cause confusion.\"],\n",
       "   'instructions': '- title=\"Draft note to marketing about product launch target date\" assignee=\"B\"\\n~ title=\"Draft note to marketing about product launch target date\" assignee=\"B\" description -> \"Write a note mentioning the target launch date of 15th, but explicitly state that it\\'s subject to final QA approval.\"\\n~ title=\"Send daily progress updates\" assignee=\"C\" due_date -> \"Until the product launch\"\\n+ title=\"Confirm no unstable payment features in demo build\" assignee=\"C\" description=\"Ensure the demo build excludes any payment features that aren\\'t finalized and is ready by Wednesday afternoon.\"'},\n",
       "  {'stage': 'repair',\n",
       "   'tasks': {'tasks': [{'title': 'Draft note to marketing about product launch target date',\n",
       "      'assignee': 'B',\n",
       "      'description': \"Write a note mentioning the target launch date of 15th, but explicitly state that it's subject to final QA approval.\",\n",
       "      'due_date': 'before the end of this week',\n",
       "      'status': 'ToDo'},\n",
       "     {'title': 'Send daily progress updates',\n",
       "      'assignee': 'C',\n",
       "      'description': 'Provide regular updates on the backend work to A and B.',\n",
       "      'due_date': 'Until the product launch',\n",
       "      'status': 'ToDo'},\n",
       "     {'title': 'Confirm no unstable payment features in demo build',\n",
       "      'assignee': 'C',\n",
       "      'description': \"Ensure the demo build excludes any payment features that aren't finalized and is ready by Wednesday afternoon.\",\n",
       "      'due_date': 'Wednesday afternoon',\n",
       "      'status': 'ToDo'}]}},\n",
       "  {'stage': 'reflect',\n",
       "   'approve': False,\n",
       "   'issues': [\"Task 'Draft note to marketing about product launch target date' has incorrect due_date; should be 'before the end of this week' based on L39.\"],\n",
       "   'instructions': '- title=\"Draft note to marketing about product launch target date\" assignee=\"B\": remove EXACT matching task if present.\\n+ title=\"Draft note to marketing about product launch target date\" assignee=\"B\" due_date=\"before the end of this week\" description=\"Write a note mentioning the target launch date of 15th, but explicitly state that it\\'s subject to final QA approval.\" status=\"ToDo\"\\n~ title=\"Send daily progress updates\" assignee=\"C\" field=\"due_date\" -> \"Until the product launch\"'},\n",
       "  {'stage': 'repair',\n",
       "   'tasks': {'tasks': [{'title': 'Send daily progress updates',\n",
       "      'assignee': 'C',\n",
       "      'description': 'Provide regular updates on the backend work to A and B.',\n",
       "      'due_date': 'Until the product launch',\n",
       "      'status': 'ToDo'},\n",
       "     {'title': 'Confirm no unstable payment features in demo build',\n",
       "      'assignee': 'C',\n",
       "      'description': \"Ensure the demo build excludes any payment features that aren't finalized and is ready by Wednesday afternoon.\",\n",
       "      'due_date': 'Wednesday afternoon',\n",
       "      'status': 'ToDo'}]}},\n",
       "  {'stage': 'reflect',\n",
       "   'approve': False,\n",
       "   'issues': [\"Task 'Send daily progress updates' lacks a specific end date. While the transcript suggests ongoing communication, the rubric requires tasks to either have a due_date or indicate an open-ended timeframe.\",\n",
       "    \"Task 'Confirm no unstable payment features in demo build' is accurate but missing the exact due date of 'next Thursday'. According to the transcript, the demo should happen next Thursday and the build needs to be prepared by Wednesday afternoon.\"],\n",
       "   'instructions': '- title=\"Send daily progress updates\" assignee=\"C\"\\n~ title=\"Confirm no unstable payment features in demo build\" assignee=\"C\" field=\"due_date\" -> \"Wednesday afternoon\"\\n+ title=\"Draft note to marketing about tentative launch date\" assignee=\"B\" description=\"Write a brief message to marketing indicating the 15th as the target launch date, subject to final QA approval.\" due_date=\"After this call\" status=\"ToDo\"\\n+ title=\"Client demo preparation\" assignee=\"C\" description=\"Prepare the demo build by Wednesday afternoon to exclude any unstable payment features and focus on internal features only.\" due_date=\"Wednesday afternoon\" status=\"ToDo\"'},\n",
       "  {'stage': 'repair',\n",
       "   'tasks': {'tasks': [{'title': 'Send daily progress updates',\n",
       "      'assignee': 'C',\n",
       "      'description': 'Provide regular updates on the backend work to A and B.',\n",
       "      'due_date': 'Until the product launch',\n",
       "      'status': 'ToDo'},\n",
       "     {'title': 'Client demo preparation',\n",
       "      'assignee': 'C',\n",
       "      'description': 'Prepare the demo build by Wednesday afternoon to exclude any unstable payment features and focus on internal features only.',\n",
       "      'due_date': 'Wednesday afternoon',\n",
       "      'status': 'ToDo'},\n",
       "     {'title': 'Draft note to marketing about tentative launch date',\n",
       "      'assignee': 'B',\n",
       "      'description': 'Write a brief message to marketing indicating the 15th as the target launch date, subject to final QA approval.',\n",
       "      'due_date': 'After this call',\n",
       "      'status': 'ToDo'}]}},\n",
       "  {'stage': 'reflect',\n",
       "   'approve': False,\n",
       "   'issues': [\"The first task's description should specify 'until the product launch' as its due date, not 'Until the product launch'.\",\n",
       "    \"The second task's title should be 'Prepare demo build excluding payment features', since it focuses on preparing an internal feature demo.\",\n",
       "    \"The third task's due date should be more specific, such as 'by end of today', given the context of drafting a note immediately after the call.\"],\n",
       "   'instructions': '- title=\"Send daily progress updates\" assignee=\"C\": remove EXACT matching task if present.\\n+ title=\"Prepare demo build excluding payment features\" assignee=\"C\" description=\"Prepare the demo build by Wednesday afternoon to exclude any unstable payment features and focus on internal features only.\" due_date=\"Wednesday afternoon\" status=\"ToDo\"\\n~ title=\"Draft note to marketing about tentative launch date\" assignee=\"B\" description=\"Write a brief message to marketing indicating the 15th as the target launch date, subject to final QA approval.\" due_date=\"After this call\" -> due_date=\"by end of today\"'}]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refl_state_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c7663b",
   "metadata": {},
   "source": [
    "By asking the model to evaluate its own output we improve task quality without changing the base model. The reflection loop demonstrates how LangGraph can route execution based on state and support iterative refinement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16008d50",
   "metadata": {},
   "source": [
    "### Persisting tasks with Langgraph Memory\n",
    "\n",
    "Our agent now produces a clean, approved TaskList. If we stop here, those tasks vanish when the run ends. In this stage we give the agent a simple long-term memory so tasks survive across runs and across transcripts. LangGraph was built for stateful, long-running agents and supports durability and memory out-of-the-box. We’ll keep it simple: a tiny key–value store for tasks, plus a dash of semantic matching so we update existing tasks instead of creating duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43c72dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "from langgraph.store.base import BaseStore           # Type for injection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307534fa",
   "metadata": {},
   "source": [
    "There are two kinds of memory to keep straight:\n",
    "\n",
    "- Checkpointing: lets the graph pause/resume during execution (e.g., across the reflection loop). That’s short-term robustness within a run.\n",
    "- Task storage: a small, persistent store where approved tasks are written so they’re still there on the next run.\n",
    "\n",
    "LangGraph’s design helps with both: durable execution and memory primitives for agent state. In our class we’ll use a lightweight local store so everyone can run this without extra services. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bc4e36",
   "metadata": {},
   "source": [
    "To keep the focus on agent logic, we use a in-memory key–value store. Each task is saved under a stable key (we’ll derive it from the `title`) and we keep the original fields (`title`, `description`, `assignee`, `due_date`, `status`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e297893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "store = InMemoryStore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9036487a",
   "metadata": {},
   "source": [
    "And a simple list tasks function to see what we got in store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6d6baae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ns(user_id: str) -> tuple[str, ...]:\n",
    "    return (\"users\", user_id, \"tasks\")\n",
    "\n",
    "def list_tasks_store(store: InMemoryStore, user_id: str, limit: int = 1000) -> List[dict]:\n",
    "    ns = _ns(user_id)\n",
    "    # No query ⇒ list; increase limit for classroom demos. :contentReference[oaicite:12]{index=12}\n",
    "    items = store.search(ns, limit=limit)\n",
    "    out = []\n",
    "    for it in items:\n",
    "        v = it.value\n",
    "        out.append({\n",
    "            \"key\": it.key,\n",
    "            \"title\": v.get(\"title\"),\n",
    "            \"description\": v.get(\"description\"),\n",
    "            \"assignee\": v.get(\"assignee\"),\n",
    "            \"due_date\": v.get(\"due_date\"),\n",
    "            \"status\": v.get(\"status\"),\n",
    "            \"score\": it.score,  # may be None if no query\n",
    "        })\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f825197e",
   "metadata": {},
   "source": [
    "Our new state includes the `persist_results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d1e9cc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "class OverallState(TypedDict, total=False):\n",
    "    transcript: str\n",
    "    summary: str\n",
    "    decisions: str\n",
    "    tasks_struct: TaskList\n",
    "    approved: bool\n",
    "    attempts: int\n",
    "    issues: List[str]\n",
    "    instructions: List[str]\n",
    "    persist_results: List[dict]\n",
    "    history: List[Dict[str, Any]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ea7f34",
   "metadata": {},
   "source": [
    "We define our persist node with key slug normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3da0d8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _slug(s: str) -> str:\n",
    "    s = \"\" if s is None else str(s)\n",
    "    s = re.sub(r\"[^a-z0-9\\s\\-_/]\", \"\", s.strip().lower())\n",
    "    s = re.sub(r\"[\\s/]+\", \"-\", s)\n",
    "    return s[:120] or \"untitled\"\n",
    "\n",
    "# Persist ALL tasks deterministically (no tool-calling needed here)\n",
    "def persist(state: OverallState, *, store: BaseStore):\n",
    "    user_id = \"u-demo\"\n",
    "    task_list = state[\"tasks_struct\"]\n",
    "    ns = _ns(user_id)\n",
    "\n",
    "    results = []\n",
    "    print(\"Persisting tasks...\")\n",
    "    for task in task_list.tasks:\n",
    "        key = _slug(task.title)\n",
    "\n",
    "        key_exists = store.get(ns, key) is not None\n",
    "        action = \"updated\" if key_exists else \"created\"\n",
    "\n",
    "        store.put(ns, key, task.model_dump())\n",
    "\n",
    "        results.append({\"action\": action, \"key\": key})\n",
    "        print(f\"  ├─ {action.upper():7} → {key} [status={task.status}]\")\n",
    "\n",
    "    return {\"persist_results\": results}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661f8f38",
   "metadata": {},
   "source": [
    "And we are ready for building our graph again.\n",
    "\n",
    "After the reflection loop approves the TaskList, the graph runs a persist node that:\n",
    "\n",
    "- iterates through tasks_struct.tasks,\n",
    "- looks up a best match in the store (semantic + lexical), and\n",
    "- upserts (update-or-insert) a single normalized record per task.\n",
    "\n",
    "Nothing here is model-dependent; it’s just deterministic logic that makes the agent feel like a real application instead of a demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2406f012",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         +-----------+            \n",
      "         | __start__ |            \n",
      "         +-----------+            \n",
      "               *                  \n",
      "               *                  \n",
      "               *                  \n",
      "         +-----------+            \n",
      "         | summarize |            \n",
      "         +-----------+            \n",
      "               *                  \n",
      "               *                  \n",
      "               *                  \n",
      "     +------------------+         \n",
      "     | tasks_structured |         \n",
      "     +------------------+         \n",
      "               *                  \n",
      "               *                  \n",
      "               *                  \n",
      "          +---------+             \n",
      "          | reflect |             \n",
      "          +---------+             \n",
      "          ..        ..            \n",
      "        ..            ..          \n",
      "       .                .         \n",
      "+--------+          +---------+   \n",
      "| repair |          | persist |   \n",
      "+--------+          +---------+   \n",
      "                          *       \n",
      "                          *       \n",
      "                          *       \n",
      "                   +-----------+  \n",
      "                   | decisions |  \n",
      "                   +-----------+  \n",
      "                          *       \n",
      "                          *       \n",
      "                          *       \n",
      "                    +---------+   \n",
      "                    | __end__ |   \n",
      "                    +---------+   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build your graph as before\n",
    "builder = StateGraph(OverallState)\n",
    "builder.add_node(\"summarize\", summarize_node)\n",
    "builder.add_node(\"tasks_structured\", tasks_structured_node_reparse)\n",
    "builder.add_node(\"reflect\", reflect_node)\n",
    "builder.add_node(\"repair\", repair_node)\n",
    "builder.add_node(\"decisions\", decisions_node)\n",
    "builder.add_node(\"persist\", persist)\n",
    "\n",
    "builder.set_entry_point(\"summarize\")\n",
    "builder.set_finish_point(\"decisions\")\n",
    "\n",
    "def _gate(state: OverallState) -> str:\n",
    "    if state.get(\"approved\") or state.get(\"attempts\", 0) >= MAX_REFLECTION_LOOPS:\n",
    "        return \"persist\"\n",
    "    return \"repair\"\n",
    "\n",
    "builder.add_edge(\"summarize\", \"tasks_structured\")\n",
    "builder.add_edge(\"tasks_structured\", \"reflect\")\n",
    "builder.add_conditional_edges(\"reflect\", _gate, {\"repair\": \"repair\", \"persist\": \"persist\"})\n",
    "builder.add_edge(\"repair\", \"reflect\")\n",
    "builder.add_edge(\"persist\", \"decisions\")\n",
    "builder.add_edge(\"decisions\", END)\n",
    "\n",
    "# 3) Compile with the store injected so nodes can receive it\n",
    "full_graph = builder.compile(store=store)\n",
    "\n",
    "# display(Image(full_graph_reflect.get_graph().draw_mermaid_png()))\n",
    "print(full_graph.get_graph().draw_ascii(), end=\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5220e309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying to parse: {\n",
      "    \"tasks\": [\n",
      "        {\n",
      "            \"title\": \"Draft note to marketing regarding product launch\",\n",
      "            \"description\": \"B will draft a short note to marketing indicating the target date for the product launch is the 15th, but subject to final QA approval.\",\n",
      "            \"assignee\": \"B\",\n",
      "            \"status\": \"ToDo\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"Send daily progress updates\",\n",
      "            \"description\": \"C will send daily progress updates to A and B so they can react quickly if there are any delays.\",\n",
      "            \"assignee\": \"C\",\n",
      "            \"status\": \"ToDo\"\n",
      "        },\n",
      "        \"title\": \"Prepare clean demo build\",\n",
      "        \"description\": \"C will ensure the demo build for the internal client demo is clean by Wednesday afternoon, excluding payment-related features.\",\n",
      "        \"assignee\": \"C\",\n",
      "        \"status\": \"ToDo\"\n",
      "    ]\n",
      "}\n",
      "tasks=[Task(title='Draft note to marketing regarding product launch', assignee='B', description='B will draft a short note to marketing indicating the target date for the product launch is the 15th, but subject to final QA approval.', due_date=None, status='ToDo'), Task(title='Send daily progress updates', assignee='C', description='C will send daily progress updates to A and B so they can react quickly if there are any delays.', due_date=None, status='ToDo'), Task(title='Prepare clean demo build', assignee='C', description='C will ensure the demo build for the internal client demo is clean by Wednesday afternoon, excluding payment-related features.', due_date=None, status='ToDo')]\n",
      "Reflection found issues (attempt 1):\n",
      " - The task 'Draft note to marketing regarding product launch' lacks specific details such as the exact wording suggested ('target date' vs 'tentative').\n",
      " - There is no task reflecting the agreement to conduct full round of regression tests by the end of next week.\n",
      " - The task 'Prepare clean demo build' incorrectly excludes payment-related features, when the transcript suggests limiting the demo to internal features only.\n",
      "\n",
      "Repair attempt 1 completed. New Tasks (n=3):\n",
      "  - Send daily progress updates [C]  due=None  status=ToDo\n",
      "  - Conduct full round of regression tests by the end of next week [C]  due=by the end of next week  status=ToDo\n",
      "  - Prepare clean demo build [C]  due=None  status=ToDo\n",
      "Reflection found issues (attempt 2):\n",
      " - Task 'Conduct full round of regression tests by the end of next week' has an incorrect assignee. It should be B since B is responsible for QA and the discussion suggests that B's team needs to conduct these tests.\n",
      " - The task 'Prepare clean demo build' should have a specific status of 'InProgress' since C has already committed to making sure the demo build is clean by Wednesday afternoon.\n",
      "\n",
      "Repair attempt 2 completed. New Tasks (n=3):\n",
      "  - Send daily progress updates [C]  due=None  status=ToDo\n",
      "  - Conduct full round of regression tests by the end of next week [B]  due=by the end of next week  status=ToDo\n",
      "  - Prepare clean demo build [C]  due=None  status=InProgress\n",
      "Reflection found issues (attempt 3):\n",
      " - Task 'Conduct full round of regression tests by the end of next week' has an incorrect assignee (B). The correct assignee should be C based on L38.\n",
      " - The description for 'Conduct full round of regression tests by the end of next week' incorrectly assigns the responsibility to B. It should mention C coordinating the team as per L38.\n",
      "\n",
      "Repair attempt 3 completed. New Tasks (n=3):\n",
      "  - Send daily progress updates [C]  due=None  status=ToDo\n",
      "  - Conduct full round of regression tests by the end of next week [C]  due=by the end of next week  status=ToDo\n",
      "  - Prepare clean demo build [C]  due=None  status=InProgress\n",
      "Persisting tasks...\n",
      "  ├─ CREATED → send-daily-progress-updates [status=ToDo]\n",
      "  ├─ CREATED → conduct-full-round-of-regression-tests-by-the-end-of-next-week [status=ToDo]\n",
      "  ├─ CREATED → prepare-clean-demo-build [status=InProgress]\n",
      "Persist results: [{'action': 'created', 'key': 'send-daily-progress-updates'}, {'action': 'created', 'key': 'conduct-full-round-of-regression-tests-by-the-end-of-next-week'}, {'action': 'created', 'key': 'prepare-clean-demo-build'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4) Run as usual\n",
    "final_state = full_graph.invoke({\"transcript\": transcript})\n",
    "print(\"Persist results:\", final_state.get(\"persist_results\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "89c9df90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'key': 'send-daily-progress-updates', 'title': 'Send daily progress updates', 'description': 'C will send daily progress updates to A and B so they can react quickly if there are any delays.', 'assignee': 'C', 'due_date': None, 'status': 'ToDo', 'score': None}\n",
      "{'key': 'conduct-full-round-of-regression-tests-by-the-end-of-next-week', 'title': 'Conduct full round of regression tests by the end of next week', 'description': 'C will coordinate the team to conduct a full round of regression tests by the end of next week, ensuring all identified issues are resolved.', 'assignee': 'C', 'due_date': 'by the end of next week', 'status': 'ToDo', 'score': None}\n",
      "{'key': 'prepare-clean-demo-build', 'title': 'Prepare clean demo build', 'description': 'C will ensure the demo build for the internal client demo is clean by Wednesday afternoon, focusing on internal features only.', 'assignee': 'C', 'due_date': None, 'status': 'InProgress', 'score': None}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Quick peek: list tasks persisted in Store\n",
    "for row in list_tasks_store(store=store, user_id=\"u-demo\"):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bc4e51",
   "metadata": {},
   "source": [
    "This short follow‑up transcript simulates a quick sync after the original meeting. We’ll re‑compile the graph with the same store and feed this new text. The goal is to update existing tasks (e.g., “notify marketing about the 15th target date”) rather than creating look‑alike duplicates with slightly different wording. Keep an eye on the ASCII graph printout: it reflects the flow we built—summarise → extract → reflect/repair → persist → decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "77ec4689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reflection found issues (attempt 1):\n",
      " - The 'Richer checkout error logs' task has an incomplete description ('Create richer checkout error logs.') which should include more context (L36).\n",
      " - The 'Stakeholder risk review' task's description is missing key details ('Book and conduct a stakeholder risk review.' should specify who conducts it and what exactly needs to be done, L58).\n",
      "\n",
      "Repair attempt 1 completed. New Tasks (n=6):\n",
      "  - Standardize daily progress updates [C]  due=None  status=ToDo\n",
      "  - Internal demo walkthrough [C]  due=Next Thursday at 11:00  status=ToDo\n",
      "  - Richer checkout error logs [C]  due=Friday EOD  status=ToDo\n",
      "  - Full regression testing [D]  due=None  status=ToDo\n",
      "  - One-pager for campaigns [B]  due=Tuesday  status=ToDo\n",
      "  - Stakeholder risk review [A]  due=Monday at 09:00  status=ToDo\n",
      "Reflection found issues (attempt 2):\n",
      " - The task 'Richer checkout error logs' has an ambiguous due_date. The original transcript specifies Friday EOD, but it lacks context indicating whether it is Friday of the current week or next week.\n",
      " - The task 'Standardize daily progress updates' does not specify a due date. However, since it's a continuous action, it should have a clear end date or a reiteration plan.\n",
      " - The task 'Full regression testing' is missing a due date. The transcript mentions kicking off Monday but doesn't specify when the report will be shared.\n",
      "\n",
      "Repair attempt 2 completed. New Tasks (n=6):\n",
      "  - Standardize daily progress updates [C]  due=Until further notice  status=ToDo\n",
      "  - Internal demo walkthrough [C]  due=Next Thursday at 11:00  status=ToDo\n",
      "  - Richer checkout error logs [C]  due=None  status=ToDo\n",
      "  - Full regression testing [D]  due=Wednesday morning  status=ToDo\n",
      "  - One-pager for campaigns [B]  due=Tuesday  status=ToDo\n",
      "  - Stakeholder risk review [A]  due=Monday at 09:00  status=ToDo\n",
      "Reflection found issues (attempt 3):\n",
      " - The title 'Standardize daily progress updates' does not reflect the specific action described ('Post a short update every day at 17:00 CET').\n",
      " - The title 'Internal demo walkthrough' lacks detail about the scope being 'internal features only'.\n",
      " - The task 'Richer checkout error logs' has no due date specified.\n",
      " - Task 'Full regression testing' has a vague due date 'Wednesday morning'; it should specify'morning' time.\n",
      " - Task 'One-pager for campaigns' should specify 'Tuesday EOD' rather than just 'Tuesday'.\n",
      "\n",
      "Repair attempt 3 completed. New Tasks (n=6):\n",
      "  - Daily progress updates at 17:00 CET [C]  due=Until further notice  status=ToDo\n",
      "  - Internal demo walkthrough [C]  due=Next Thursday at 11:00  status=ToDo\n",
      "  - Richer checkout error logs [C]  due=Friday EOD  status=ToDo\n",
      "  - Full regression testing [D]  due=Wednesday morning at 09:00  status=ToDo\n",
      "  - One-pager for campaigns [B]  due=Tuesday EOD  status=ToDo\n",
      "  - Stakeholder risk review [A]  due=Monday at 09:00  status=ToDo\n",
      "Persisting tasks...\n",
      "  ├─ CREATED → daily-progress-updates-at-1700-cet [status=ToDo]\n",
      "  ├─ CREATED → internal-demo-walkthrough [status=ToDo]\n",
      "  ├─ CREATED → richer-checkout-error-logs [status=ToDo]\n",
      "  ├─ CREATED → full-regression-testing [status=ToDo]\n",
      "  ├─ CREATED → one-pager-for-campaigns [status=ToDo]\n",
      "  ├─ CREATED → stakeholder-risk-review [status=ToDo]\n",
      "Persist results: [{'action': 'created', 'key': 'daily-progress-updates-at-1700-cet'}, {'action': 'created', 'key': 'internal-demo-walkthrough'}, {'action': 'created', 'key': 'richer-checkout-error-logs'}, {'action': 'created', 'key': 'full-regression-testing'}, {'action': 'created', 'key': 'one-pager-for-campaigns'}, {'action': 'created', 'key': 'stakeholder-risk-review'}]\n"
     ]
    }
   ],
   "source": [
    "follow_up_transcript = \"\"\"\n",
    "A: Quick sync. First—B, the marketing email about the 15th target date?\n",
    "B: I have done that, I sent it right after our last call and posted in #marketing. If QA slips, I'll post an update.\n",
    "C: Noted.\n",
    "A: Daily progress updates—can we standardize them?\n",
    "C: Yes. I'll post a short update every day at 17:00 CET in the #launch-updates thread with error rate and blockers. We will keep it in progress.\n",
    "A: Perfect.\n",
    "A: What about the Demo build status?\n",
    "C: Finished Tuesday EOD; it's clean and payments stay disabled. So that task's done.\n",
    "A: Next Thursday's client demo—let's keep it internal features only. C, can you lead the walkthrough? I'll handle intros and Q&A. Let's set it for 11:00.\n",
    "C: Works for me.\n",
    "D (QA): We can kick off full regression Monday and aim to share the report by Wednesday morning.\n",
    "A: Perfect.\n",
    "C: To speed triage we need richer checkout error logs; I can take that.\n",
    "A: Please aim for Friday EOD.\n",
    "B: After QA sign-off, design wants a one-pager to brief campaigns. I'll draft it Tuesday.\n",
    "A: And let's have a stakeholder risk review Monday at 09:00—I'll book it.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "final_state = full_graph.invoke({\"transcript\": follow_up_transcript})\n",
    "print(\"Persist results:\", final_state.get(\"persist_results\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bf359a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'key': 'send-daily-progress-updates', 'title': 'Send daily progress updates', 'description': 'C will send daily progress updates to A and B so they can react quickly if there are any delays.', 'assignee': 'C', 'due_date': None, 'status': 'ToDo', 'score': None}\n",
      "{'key': 'conduct-full-round-of-regression-tests-by-the-end-of-next-week', 'title': 'Conduct full round of regression tests by the end of next week', 'description': 'C will coordinate the team to conduct a full round of regression tests by the end of next week, ensuring all identified issues are resolved.', 'assignee': 'C', 'due_date': 'by the end of next week', 'status': 'ToDo', 'score': None}\n",
      "{'key': 'prepare-clean-demo-build', 'title': 'Prepare clean demo build', 'description': 'C will ensure the demo build for the internal client demo is clean by Wednesday afternoon, focusing on internal features only.', 'assignee': 'C', 'due_date': None, 'status': 'InProgress', 'score': None}\n",
      "{'key': 'daily-progress-updates-at-1700-cet', 'title': 'Daily progress updates at 17:00 CET', 'description': 'Post a short update every day at 17:00 CET in the #launch-updates thread.', 'assignee': 'C', 'due_date': 'Until further notice', 'status': 'ToDo', 'score': None}\n",
      "{'key': 'internal-demo-walkthrough', 'title': 'Internal demo walkthrough', 'description': 'Lead the walkthrough focusing on internal features only.', 'assignee': 'C', 'due_date': 'Next Thursday at 11:00', 'status': 'ToDo', 'score': None}\n",
      "{'key': 'richer-checkout-error-logs', 'title': 'Richer checkout error logs', 'description': 'To speed triage, create richer checkout error logs.', 'assignee': 'C', 'due_date': 'Friday EOD', 'status': 'ToDo', 'score': None}\n",
      "{'key': 'full-regression-testing', 'title': 'Full regression testing', 'description': 'Kick off full regression testing and aim to share the report by Wednesday morning at 09:00.', 'assignee': 'D', 'due_date': 'Wednesday morning at 09:00', 'status': 'ToDo', 'score': None}\n",
      "{'key': 'one-pager-for-campaigns', 'title': 'One-pager for campaigns', 'description': 'Draft a one-pager to brief campaigns.', 'assignee': 'B', 'due_date': 'Tuesday EOD', 'status': 'ToDo', 'score': None}\n",
      "{'key': 'stakeholder-risk-review', 'title': 'Stakeholder risk review', 'description': 'Book and conduct a stakeholder risk review at 09:00 on Monday.', 'assignee': 'A', 'due_date': 'Monday at 09:00', 'status': 'ToDo', 'score': None}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Quick peek: list tasks persisted in Store\n",
    "for row in list_tasks_store(store=store, user_id=\"u-demo\"):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ebef02",
   "metadata": {},
   "source": [
    "But we see it repeated some tasks that should be refering to the same thing! Let's fix that with semantic search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78d7f26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = InMemoryStore(\n",
    "    index={\"dims\": 768, \"embed\": embed, \"fields\": [\"title\", \"description\"]}  # optional\n",
    ")\n",
    "\n",
    "USER_ID = \"u-demo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2cc8a4",
   "metadata": {},
   "source": [
    "Find a match key (vector search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2cb15cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the store's vector index (title→embedding) to find nearest neighbor.\n",
    "SIM_THRESHOLD = 0.7\n",
    "\n",
    "def _nearest_title(store: BaseStore, ns: tuple, title: str):\n",
    "    \"\"\"Return (key, score) for the nearest existing task title, or (None, None).\"\"\"\n",
    "    hits = store.search(ns, query=title, limit=1) or []\n",
    "    if not hits:\n",
    "        return None, None\n",
    "    h = hits[0]\n",
    "    \n",
    "    return h.key, getattr(h, \"score\", None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0064467",
   "metadata": {},
   "source": [
    "Semantic upsert persist node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4ef979e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def persist_semantic(state: OverallState, *, store: BaseStore):\n",
    "    user_id = USER_ID\n",
    "    ns = (\"users\", user_id, \"tasks\")\n",
    "    task_list = state.get(\"tasks_struct\")\n",
    "    results = []\n",
    "    \n",
    "    print(\"Persisting (semantic upsert)…\")\n",
    "    for task in task_list.tasks:\n",
    "        match_key, score = _nearest_title(store, ns, task.title)\n",
    "        use_match = (score is not None) and (score >= SIM_THRESHOLD)\n",
    "\n",
    "        key = match_key if use_match else _slug(task.title)\n",
    "        action = \"updated\" if use_match else \"created\"\n",
    "\n",
    "        store.put(ns, key, task.model_dump())  # uses the index fields you configured\n",
    "        results.append({\"action\": action, \"key\": key, \"score\": score})\n",
    "\n",
    "        print(f\"  ├─ {action.upper():7} → {key} [status={task.status}] (score={None if score is None else round(score, 3)})\")\n",
    "\n",
    "    return {\"persist_results\": results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b4e6722d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    +-----------+    \n",
      "    | __start__ |    \n",
      "    +-----------+    \n",
      "          *          \n",
      "          *          \n",
      "          *          \n",
      "    +-----------+    \n",
      "    | summarize |    \n",
      "    +-----------+    \n",
      "          *          \n",
      "          *          \n",
      "          *          \n",
      "+------------------+ \n",
      "| tasks_structured | \n",
      "+------------------+ \n",
      "          *          \n",
      "          *          \n",
      "          *          \n",
      "    +---------+      \n",
      "    | reflect |      \n",
      "    +---------+      \n",
      "          *          \n",
      "          *          \n",
      "          *          \n",
      "    +---------+      \n",
      "    | __end__ |      \n",
      "    +---------+      \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build your graph as before\n",
    "builder = StateGraph(OverallState)\n",
    "builder.add_node(\"summarize\", summarize_node)\n",
    "builder.add_node(\"tasks_structured\", tasks_structured_node_reparse)\n",
    "builder.add_node(\"reflect\", reflect_node)\n",
    "builder.add_node(\"repair\", repair_node)\n",
    "builder.add_node(\"decisions\", decisions_node)\n",
    "builder.add_node(\"persist_semantic\", persist_semantic)\n",
    "\n",
    "builder.set_entry_point(\"summarize\")\n",
    "builder.set_finish_point(\"decisions\")\n",
    "\n",
    "def _gate(state: OverallState) -> str:\n",
    "    if state.get(\"approved\") or state.get(\"attempts\", 0) >= MAX_REFLECTION_LOOPS:\n",
    "        return \"persist_semantic\"\n",
    "    return \"repair\"\n",
    "\n",
    "builder.add_edge(\"summarize\", \"tasks_structured\")\n",
    "builder.add_edge(\"tasks_structured\", \"reflect\")\n",
    "builder.add_conditional_edges(\"reflect\", _gate)\n",
    "builder.add_edge(\"repair\", \"reflect\")\n",
    "builder.add_edge(\"persist_semantic\", \"decisions\")\n",
    "builder.add_edge(\"decisions\", END)\n",
    "\n",
    "# 3) Compile with the store injected so nodes can receive it\n",
    "full_graph = builder.compile(store=store)\n",
    "\n",
    "# display(Image(full_graph_reflect.get_graph().draw_mermaid_png()))\n",
    "print(full_graph.get_graph().draw_ascii(), end=\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9a6087ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying to parse: {\n",
      "    \"tasks\": [\n",
      "        {\n",
      "            \"title\": \"Draft a note to marketing regarding the product launch\",\n",
      "            \"description\": \"Draft a note mentioning the target date of the 15th for the product launch, but emphasize that it's subject to final QA approval.\",\n",
      "            \"assignee\": \"B\",\n",
      "            \"due_date\": \"Today\",\n",
      "            \"status\": \"ToDo\"\n",
      "        },\n",
      "        {\n",
      "            \"title\": \"Send daily progress updates\",\n",
      "            \"description\": \"Provide daily updates on the progress of fixing backend issues to A and B.\",\n",
      "            \"assignee\": \"C\",\n",
      "            \"due_date\": \"Until further notice\",\n",
      "            \"status\": \"ToDo\"\n",
      "        },\n",
      "        \"title\": \"Prepare a demo for internal features\",\n",
      "        \"description\": \"Ensure that the demo build does not include any payment-related features and is clean by Wednesday afternoon.\",\n",
      "        \"assignee\": \"C\",\n",
      "        \"due_date\": \"Wednesday\",\n",
      "        \"status\": \"ToDo\"\n",
      "    ]\n",
      "}\n",
      "tasks=[Task(title='Draft a note to marketing regarding the product launch', assignee='B', description=\"Draft a note mentioning the target date of the 15th for the product launch, but emphasize that it's subject to final QA approval.\", due_date='Today', status='ToDo'), Task(title='Send daily progress updates', assignee='C', description='Provide daily updates on the progress of fixing backend issues to A and B.', due_date='Until further notice', status='ToDo'), Task(title='Prepare a demo for internal features', assignee='C', description='Ensure that the demo build does not include any payment-related features and is clean by Wednesday afternoon.', due_date='Wednesday', status='ToDo')]\n",
      "Reflection found issues (attempt 1):\n",
      " - The task 'Draft a note to marketing regarding the product launch' has a due_date of 'Today', which contradicts the discussion where B was asked to draft the note after the meeting.\n",
      " - There's no task representing A's directive to limit the demo to internal features only, avoiding payment-related aspects until they are confirmed stable.\n",
      "\n",
      "Repair attempt 1 completed. New Tasks (n=3):\n",
      "  - Draft a note to marketing regarding the product launch [B]  due=Today  status=ToDo\n",
      "  - Send daily progress updates [C]  due=Until further notice  status=ToDo\n",
      "  - Limit demo to internal features [C]  due=Next Thursday  status=ToDo\n",
      "Reflection found issues (attempt 2):\n",
      " - The first task's due_date should be 'Today' without specifying a particular date, as it is implied to be completed immediately after the discussion.\n",
      " - The second task has an incorrect due_date format. It should be 'Until further notice' rather than specifying a fixed duration.\n",
      " - The third task's description does not match the transcript exactly. The transcript specifies limiting the demo to internal features and excluding payment-related features until they are confirmed stable.\n",
      "\n",
      "Repair attempt 2 completed. New Tasks (n=3):\n",
      "  - Send daily progress updates [C]  due=Until further notice  status=ToDo\n",
      "  - Limit demo to internal features [C]  due=Next Thursday  status=ToDo\n",
      "  - Draft a note to marketing regarding the product launch [B]  due=Today  status=ToDo\n",
      "Reflection found issues (attempt 3):\n",
      " - The title 'Limit demo to internal features' does not match the description provided in the transcript.\n",
      " - The description for 'Draft a note to marketing regarding the product launch' is accurate but should specify that it's a short note.\n",
      " - The status of 'Limit demo to internal features' is set to 'ToDo', but the task seems to be more of a reminder or a precaution rather than an actionable item.\n",
      "\n",
      "Repair attempt 3 completed. New Tasks (n=2):\n",
      "  - Send daily progress updates [C]  due=Until further notice  status=ToDo\n",
      "  - Draft a note to marketing regarding the product launch [B]  due=Today  status=ToDo\n",
      "Persisting (semantic upsert)…\n",
      "  ├─ CREATED → send-daily-progress-updates [status=ToDo] (score=None)\n",
      "  ├─ CREATED → draft-a-note-to-marketing-regarding-the-product-launch [status=ToDo] (score=0.497)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_state = full_graph.invoke({\"transcript\": transcript})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e49ec0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reflection found issues (attempt 1):\n",
      " - The 'Marketing Email' task is missing.\n",
      " - The 'Demo build status' should be marked as 'Done'.\n",
      " - Task 'Next Thursday's client demo' should include A's role of handling intros and Q&A.\n",
      "\n",
      "Repair attempt 1 completed. New Tasks (n=6):\n",
      "  - Standardize daily progress updates [C]  due=None  status=ToDo\n",
      "  - Next Thursday's client demo [C]  due=None  status=ToDo\n",
      "  - Full regression testing [D]  due=None  status=ToDo\n",
      "  - Richer checkout error logs [C]  due=Friday EOD  status=ToDo\n",
      "  - One-pager for campaign briefing [B]  due=Tuesday  status=ToDo\n",
      "  - Stakeholder risk review [A]  due=None  status=ToDo\n",
      "Reflection found issues (attempt 2):\n",
      " - Task 'Next Thursday's client demo' should have its due_date field set to 'Thursday'.\n",
      " - Task 'Richer checkout error logs' has a typo in the description field, it should read'speed triage' rather than'speed up triage'.\n",
      " - Task 'One-pager for campaign briefing' has an incorrect due_date. It should be 'Tuesday EOD', not just 'Tuesday'.\n",
      "\n",
      "Repair attempt 2 completed. New Tasks (n=6):\n",
      "  - Standardize daily progress updates [C]  due=None  status=ToDo\n",
      "  - Next Thursday's client demo [C]  due=Thursday  status=ToDo\n",
      "  - Full regression testing [D]  due=None  status=ToDo\n",
      "  - Richer checkout error logs [C]  due=Friday EOD  status=ToDo\n",
      "  - One-pager for campaign briefing [B]  due=Tuesday EOD  status=ToDo\n",
      "  - Stakeholder risk review [A]  due=None  status=ToDo\n",
      "Reflection found issues (attempt 3):\n",
      " - The task 'Richer checkout error logs' has an incorrect due_date format. It should be 'Friday EOD' instead of 'Friday EOD'.\n",
      " - Task 'Next Thursday's client demo' does not specify a time. According to the transcript, the demo is scheduled for 11:00.\n",
      " - There's no task for the 'Marketing email about the 15th target date', which B mentioned as completed.\n",
      "\n",
      "Repair attempt 3 completed. New Tasks (n=6):\n",
      "  - Standardize daily progress updates [C]  due=None  status=ToDo\n",
      "  - Next Thursday's client demo [C]  due=Thursday  status=ToDo\n",
      "  - Full regression testing [D]  due=None  status=ToDo\n",
      "  - Richer checkout error logs [C]  due=None  status=ToDo\n",
      "  - One-pager for campaign briefing [B]  due=Tuesday EOD  status=ToDo\n",
      "  - Stakeholder risk review [A]  due=None  status=ToDo\n",
      "Persisting (semantic upsert)…\n",
      "  ├─ UPDATED → send-daily-progress-updates [status=ToDo] (score=0.838)\n",
      "  ├─ CREATED → next-thursdays-client-demo [status=ToDo] (score=0.56)\n",
      "  ├─ CREATED → full-regression-testing [status=ToDo] (score=0.442)\n",
      "  ├─ CREATED → richer-checkout-error-logs [status=ToDo] (score=0.448)\n",
      "  ├─ CREATED → one-pager-for-campaign-briefing [status=ToDo] (score=0.598)\n",
      "  ├─ CREATED → stakeholder-risk-review [status=ToDo] (score=0.535)\n"
     ]
    }
   ],
   "source": [
    "final_state = full_graph.invoke({\"transcript\": follow_up_transcript})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7552edb",
   "metadata": {},
   "source": [
    "## Wrap‑up and next steps\n",
    "\n",
    "We began with a simple prompt and iteratively built a small, working agentic system that parses a messy meeting transcript and outputs a clean summary, a structured task list, and recorded decisions. Along the way you learned how to:\n",
    "- Decompose a complex task into modular nodes (summary → tasks → decisions) and wire them together with LangGraph.\n",
    "- Add a critic/repair loop to improve quality before persisting results.\n",
    "- Persist results across runs using a lightweight memory store and a “semantic upsert” keyed on task titles.\n",
    "\n",
    "This pattern—**decompose, validate, reflect, and persist**—is a reusable template for many agentic workflows.\n",
    "\n",
    "### Stretch exercise: refine the semantic matcher\n",
    "\n",
    "Our current semantic upsert matches tasks based only on their titles. As you saw earlier, this can still produce duplicates when two tasks have different wording but the same intent. For a challenge, think about how you might incorporate the task descriptions into the similarity search. Where in the code would you need to make changes? How would you decide when to fall back on the description? Try modifying your graph accordingly, re‑run it on the follow‑up transcript, and see if fewer duplicates remain. Let me know how it goes—or take it as a take‑home challenge!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
